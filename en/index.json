[
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Vu Nguyen Binh\nPhone Number: 0784216914\nEmail: vunguyenbinh25@gmail.com\nUniversity: FPT University\nMajor: Information Assurance\nClass: AWS092025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 8/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Understanding the UK Critical Third Parties (CTPs) Regime: What Customers Need to Know On November 12, 2024, the UK financial services regulators ‚Äî the Bank of England (BoE), the Prudential Regulation Authority (PRA), and the Financial Conduct Authority (FCA) ‚Äî published the final documents for the UK Critical Third Parties (CTPs) regime. These documents clarify how the regime will be implemented and expand regulatory oversight to specific services that designated CTPs provide to the UK financial sector.\nAWS is preparing to comply with this regime, assuming it will be designated as a CTP.\nKey Regulatory Changes Two core documents define the regime:\nSupervisory Statement (SS) 6/24 Critical Third Parties Instrument The Instrument sets the mandatory requirements for designated CTPs, while SS6/24 provides guidance on interpreting and implementing those requirements. Together, they form the operational foundation for the new supervisory approach.\nWhat the Regime Introduces One of the most significant updates is the introduction of Systemic Third-Party Services (STPS) ‚Äî services whose disruption could threaten the stability or confidence of the UK financial system.\nDesignated CTPs must meet detailed requirements for STPS, including:\nConducting scenario testing Running incident management playbook exercises Sharing relevant information with regulators The regime becomes effective 1 January 2025, but will only apply after a provider is formally designated. The designation process will take at least six months, with the first designations expected around mid-2025.\nOnce designated, a CTP has three months to submit its first self-assessment report on STPS compliance.\nThe regulatory approach is aligned with international standards and ensures interoperability with other jurisdictions.\nOverall Objective of the Regime The regime aims to address systemic third-party concentration risk ‚Äî the risk that a small number of external providers supply critical services to many financial institutions.\nIt builds on existing expectations set out in:\nSS1/21 SS2/21 The Operational Resilience policy statement These documents shape how financial institutions manage outsourcing, third-party risk, and impact tolerances for important business services.\nAWS Commitment This outcomes-based regime provides CTPs with flexibility in how they demonstrate compliance. It does not increase the regulatory burden on financial institutions, but supports a stronger, more resilient UK financial system.\nAWS fully supports the regulators‚Äô objectives and values the continued engagement throughout this process. We are committed to:\nMeeting all regulatory requirements Helping customers understand AWS‚Äôs approach to the CTP regime Supporting customers in improving their operational resilience Impact on Customers Regulators have clarified that the regime does not remove or reduce the responsibilities of financial institutions, their boards, or senior management.\nImportantly, it does not impose new obligations directly on AWS customers.\nHowever, customers should expect to:\nProvide accurate information about their third-party dependencies Review and update their risk management and due-diligence processes Leverage new information shared by CTPs under the regime AWS already provides a wide range of services that support effective incident management, across both cloud-native and hybrid environments.\nGuidance on incident management is also available in the AWS Well-Architected Framework.\nIf you have questions about the regime or operational resilience practices ‚Äî including incident management ‚Äî contact your AWS account team.\nAbout the Authors Michael Jefferson Michael Jefferson is the Head of Public Policy for Financial Services at AWS, covering the UK, Middle East, Africa, and Switzerland. He co-leads AWS\u0026rsquo;s engagement with the Financial Stability Board (FSB). His background spans technology, industry associations, investment banking, and the UK public sector.\nArvind Kannan Arvind Kannan is a Principal Compliance Specialist at AWS based in London. He works closely with financial services customers across EMEA, focusing on governance, risk, compliance, and operational resilience, helping them navigate increasingly complex regulatory expectations.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Sharing the Vision of a More Connected World with AWS IoT Interview with Yasser Alsaied ‚Äî Vice President of IoT at Amazon Web Services (AWS)\nIntroduction The future of the Internet of Things (IoT) is a widely discussed topic, relevant to hyperscalers, solution providers, and enterprise customers. To clarify the big picture, we explore the perspective of Yasser Alsaied, Vice President of IoT at AWS, on strategy, vision, and ecosystem development.\nYasser\u0026rsquo;s Role and Experience at AWS Yasser has 32 years of experience in technology and IoT.\nHe joined AWS in 2021 and oversees all IoT domains including:\nRobotics Industrial Automotive Consumer Public Sector Commercial AWS IoT services are part of one of the largest globally connected solution portfolios, supporting digital twins, smart cities, and connected vehicles.\nPreviously, Yasser was VP of IoT at Qualcomm, leading AI, computer vision, drones, robotics, and 5G development in the IoT chipset ecosystem.\nIndustry Shifts and Customer Impact According to Yasser, IoT continues to grow rapidly, but hyperscalers are shifting focus from horizontal solutions to vertical, industry-specific solutions.\n‚ÄúCustomers don‚Äôt come to ask for IoT ‚Äî they come to achieve business outcomes.‚Äù\nThis forces cloud providers to frame IoT in the context of each industry, with its unique challenges and needs.\nAWS IoT Strategy: Industry-Centric Approach AWS sees an industry-centric strategy as the ‚ÄúNorth Star‚Äù, reflected in:\nAWS IoT SiteWise / TwinMaker ‚Üí Industrial IoT AWS IoT FleetWise ‚Üí Automotive Partnerships with industry-specific technology providers AWS restructures products and support to fit each vertical, optimizing the customer experience.\nImportance of Industry-Specific Solutions IoT customers often face challenges in:\nMoving from PoC ‚Üí production Scaling operations System integration AWS addresses these via:\nAWS \u0026amp; Partner Solutions: sample code, reference architectures ISVs: prebuilt software SIs: integration and customization This enables faster deployment, easier scaling, and cost savings.\nAWS Investment Focus In the past 2 years, AWS launched numerous IoT services:\nAWS IoT FleetWise AWS IoT ExpressLink AWS IoT TwinMaker AWS IoT Core for Amazon Sidewalk Over 50 new IoT features IoT service price reductions The IoT device partner ecosystem exceeds 800 compatible devices.\nAWS continues to focus on:\nüåê 1. Edge Computing AWS IoT SiteWise Edge AWS IoT Greengrass Low-latency, on-site data processing Use cases: factories, 5G towers, on-prem data centers üîÑ 2. Hybrid Cloud Extend APIs, tools, and infrastructure to edge locations Support CapEx ‚Üí OpEx transformation Why IoT Matters to Amazon Amazon uses AWS IoT across its core operations:\nüöö Logistics \u0026amp; Fulfillment 300+ operational facilities 750,000+ autonomous robots 1.6 million packages/day üõª Fleet Optimization Using "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Create a gateway endpoint",
	"tags": [],
	"description": "",
	"content": " Open the Amazon VPC console In the navigation pane, choose Endpoints, then click Create Endpoint: You will see 6 existing VPC endpoints that support AWS Systems Manager (SSM). These endpoints were deployed automatically by the CloudFormation Templates for this workshop.\nIn the Create endpoint console: Specify name of the endpoint: s3-gwe In service category, choose AWS services In Services, type s3 in the search box and choose the service with type gateway For VPC, select VPC Cloud from the drop-down. For Configure route tables, select the route table that is already associated with two subnets (note: this is not the main route table for the VPC, but a second route table created by CloudFormation). For Policy, leave the default option, Full Access, to allow full access to the service. You will deploy a VPC endpoint policy in a later lab module to demonstrate restricting access to S3 buckets based on policies. Do not add a tag to the VPC endpoint at this time. Click Create endpoint, then click x after receiving a successful creation message. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Summary Report: ‚ÄúAWS Cloud Mastery Series #1‚Äù Event Objectives AWS AI/ML Services Overview Generative AI with Amazon Bedrock Key Highlights Understanding the AI/ML Landscape \u0026amp; AWS Ecosystem Overview of AI/ML/GenAI adoption trends in Vietnam\nImportance of standardized ML workflows for modern applications\nIntroduction to the workshop agenda and learning goals\nAWS AI/ML Services Overview The session provided a comprehensive deep dive into core AWS ML services:\nAmazon SageMaker ‚Äì End-to-end ML platform for building, training, tuning, and deploying - - models\nData preparation \u0026amp; labeling ‚Äì Ensuring high-quality datasets for optimal model performance\nIntegrated MLOps ‚Äì CI/CD for AI, model registry, experiment tracking, and monitoring\nLive Demo ‚Äì SageMaker Studio walkthrough: creating notebooks, training, deployment workflows\nGenerative AI with Amazon Bedrock A thorough exploration of the GenAI ecosystem on AWS:\nFoundation Models (Claude, Llama, Titan): comparison, strengths, and how to select the right model\nPrompt Engineering Techniques:\nCore prompting strategies\nFew-shot prompting\nChain-of-Thought reasoning\nRAG (Retrieval-Augmented Generation)\nArchitecture for enterprise knowledge integration\nBuilding effective Knowledge Bases\nBedrock Agents\nHandling multi-step workflows\nIntegrating tools and external systems\nGuardrails\nSafety policies, content filtering, and compliance\nLive Demo\nBuilding a fully functional Generative AI chatbot using Bedrock\nKey Takeaways Design Mindset AI-first approach: Begin with the business problem, then tailor the model and architecture\nResponsible AI: Safety, compliance, and ethical AI are critical in production environments\nUbiquitous language for AI: Shared vocabulary across Data, ML, DevOps, and Business teams\nTechnical Architecture Modern AI/ML pipeline: data ingestion ‚Üí preprocessing ‚Üí training ‚Üí deployment ‚Üí monitoring\nRAG \u0026amp; Bedrock Agents: Strategies for building enterprise-ready chatbots and AI assistants\nIntegration Patterns: Choosing the right Foundation Model and connecting it with application data\nMLOps Principles: Automating ML workflows to reduce errors, improve model reproducibility, and accelerate development\nModernization Strategy Standardizing ML workflows with SageMaker\nImplementing Guardrails for safe and compliant GenAI applications\nCost optimization through model selection and automated training workflows\nReal-world use cases: Chatbots, content classification, customer support automation, internal knowledge retrieval\nApplying to Work Build end-to-end ML pipelines with SageMaker and integrated MLOps\nApply RAG to enhance enterprise search and internal knowledge systems\nCreate GenAI chatbots for business workflows\nEvaluate Foundation Models based on latency, accuracy, and cost\nIntegrate Amazon Bedrock into existing applications to automate tasks and improve productivity\nEvent Experience Attending AWS Cloud Mastery Series #1 provided a holistic view of how AI/ML and GenAI are built, deployed, and scaled on AWS. Key experiences included:\nLearning from AWS Experts AWS Vietnamese experts shared in-depth insights into the AI/ML ecosystem and real-world deployment patterns\nPractical case studies helped clarify how to select models, design pipelines, and ensure safe AI practices\nHands-on technical exposure The SageMaker Studio Demo illustrated the complete ML lifecycle\nClear understanding of RAG architecture, Bedrock Agents, and Foundation Model selection\nPractical exercises in prompt engineering with modern techniques\nExploring Modern Tools Learned how to build a GenAI chatbot quickly using Bedrock\nUnderstood how Guardrails ensure safe and responsible AI behavior\nMeaningful Networking The workshop created spaces to exchange ideas with AWS professionals and AI/ML practitioners\nStrengthened the ubiquitous language between technical and business teams\nLessons learned GenAI solutions require a complete architecture, not just a model\nRAG greatly improves the accuracy of enterprise GenAI applications\nMLOps is essential for scaling ML in production\nFoundation Models should be chosen based on real business requirements‚Äînot trends\nThe workshop not only delivered strong technical knowledge but also reshaped my mindset on building AI/ML applications, deploying GenAI responsibly, and leveraging the AWS ecosystem effectively.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Summary Report: ‚ÄúAWS Cloud Mastery Series #2‚Äù Event Objectives DevOps Culture \u0026amp; Mindset\nCI/CD Pipeline with AWS DevOps Services\nInfrastructure as Code (IaC)\nContainers, Monitoring, and Observability\nKey Highlights DevOps Mindset \u0026amp; Cultural Foundations The morning began with a recap of the previous AI/ML session, followed by an introduction to the DevOps culture, emphasizing:\nCollaboration and shared ownership across teams\nAutomation, continuous improvement, and fast feedback loops\nKey DevOps performance metrics such as DORA, MTTR, and deployment frequency\nThis set the foundation for understanding why DevOps is critical for building scalable, resilient, and high-velocity engineering organizations.\nAWS DevOps Services ‚Äì CI/CD Pipeline The session covered the full spectrum of AWS-native DevOps tools:\nSource Control: AWS CodeCommit and Git workflows such as GitFlow and Trunk-based development\nBuild \u0026amp; Test: CodeBuild configuration, unit/integration testing in pipelines\nDeployment:\nCodeDeploy with blue/green deployments\nCanary and Rolling updates for safe production rollouts\nOrchestration: CodePipeline to automate the entire CI/CD lifecycle\nLive Demo: End-to-end CI/CD pipeline from commit to production deployment\nThis reinforced how automation reduces operational load and increases delivery speed.\nInfrastructure as Code (IaC) A deep dive into IaC best practices on AWS:\nAWS CloudFormation: Templates, stacks, and monitoring drift in deployed resources\nAWS CDK:\nUsing high-level constructs\nReusable patterns\nMulti-language support (TypeScript, Python, Java, etc.)\nLive Demo: Provisioning infrastructure using both CloudFormation and CDK\nDiscussion: When to choose CloudFormation vs CDK depending on team skills and project needs\nKey Takeaways DevOps Mindset Automation-first approach: Reduce manual operations, improve consistency Continuous delivery: Smaller batch deployments reduce risk and speed up iteration Metrics-driven decision making(DORA, MTTR): Improve performance based on measurable data Technical Architecture CI/CD Pipelines: Best practices for high-quality software delivery IaC Reproducibility, version control, and reduced configuration drift Container orchestration: How to select between ECS, EKS, and App Runner Observability stack: Full visibility across systems for debugging and performance optimization Modernization Strategy Adopt microservices + containerization with ECS/EKS\nUse IaC to standardize infrastructure across environments\nImprove deployment safety with blue/green, canary, and automated testing\nStrengthen incident management with observability and postmortems\nApplying to Work Implement CI/CD using CodePipeline, CodeBuild, and CodeDeploy\nUse IaC (CloudFormation/CDK) for all environments to eliminate manual setup\nContainerize applications and evaluate ECS/EKS vs App Runner depending on complexity\nSet up CloudWatch dashboards and X-Ray tracing for full-stack observability\nApply DevOps best practices: feature flags, A/B testing, automated rollbacks\nEvent Experience The AWS Cloud Mastery Series #2 provided a comprehensive and practical understanding of how DevOps principles are implemented at scale using AWS services. Key experiences include:\nLearning from AWS experts Speakers shared real-world DevOps transformations from both startups and enterprises\nGained deep insight into deployment strategies and why modern teams move toward continuous delivery\nUnderstood the value of combining DevOps culture with AWS automation tools\nHands-on technical demos Full CI/CD pipeline walkthrough from source code to production\nStep-by-step IaC deployment using CloudFormation and CDK\nContainer deployment demos comparing ECS, EKS, and App Runner\nComplete observability setup with CloudWatch and X-Ray\nThese demos clarified how teams can build highly-automated, reliable pipelines.\nExploring modern container and observability tools Learned how Docker accelerates microservices development\nUnderstood the role of ECR in image scanning and security\nBuilt monitoring dashboards and traced distributed systems using X-Ray\nBest practices and real-world examples Discussed incident response, root cause analysis, and postmortem culture\nReviewed enterprise DevOps journeys and lessons learned\nLearned the importance of feature flags, A/B testing, and automated deployments\nLessons learned DevOps is not just tools‚Äîit is culture, automation, and continuous improvement\nIaC is essential for speed, scalability, and precision\nContainers and CI/CD pipelines accelerate product delivery\nObservability is key to reliability and operational excellence\nOverall, the event provided not only technical knowledge but also a strong foundation in DevOps culture, deployment automation, infrastructure management, and monitoring practices on AWS.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Summary Report: ‚ÄúAWS Well-Architected Framework ‚Äì Security Pillar Workshop‚Äù Event Objectives Deep-dive into the Security Pillar of the AWS Well-Architected Framework\nUnderstand modern security best practices: Least Privilege, Zero Trust, Defense in Depth\nLearn how to design secure cloud environments with Identity, Detection, Infrastructure Protection, Data Protection, and Incident Response pillars\nKey Highlights Security Foundation Explained the role of the Security Pillar within the Well-Architected Framework Core principles: Least Privilege ‚Äî minimize access permissions\nZero Trust ‚Äî never trust, always verify\nDefense in Depth ‚Äî layered security approach\nReview of the Shared Responsibility Model and how it applies to AWS services Overview of common cloud threats in Vietnam, including misconfigurations, credential compromise, and public-data exposure Pillar 1 ‚Äî Identity \u0026amp; Access Management (IAM) Modern IAM Architecture:\nIAM concepts: Users, Roles, Policies, and avoiding long-term credentials\nIdentity modernization with IAM Identity Center (SSO, permission sets)\nGovernance for multi-account environments via Service Control Policies (SCP) and permission boundaries\nStrengthening access control with MFA, credential rotation, and Access Analyzer\nMini Demo: IAM Policy validation and access simulation\nPillar 2 ‚Äî Detection Detection \u0026amp; Continuous Monitoring:\nUnified logging and monitoring using: CloudTrail (organization-level)\nGuardDuty threat detection\nSecurity Hub compliance findings\nLogging across all layers: VPC Flow Logs, ALB logs, S3 Access Logs\nAutomated alerting with EventBridge\nConcept of Detection-as-Code for repeatable and auditable monitoring rules\nPillar 3 ‚Äî Infrastructure Protection Network \u0026amp; Workload Security:\nDesigning secure networks with VPC segmentation and correct use of public vs private subnets\nComparison of Security Groups vs NACLs with recommended patterns\nLayers of perimeter defense: AWS WAF, Shield, Network Firewall\nWorkload-level protection for EC2, ECS, and EKS environments\nPillar 4 ‚Äî Data Protection Encryption, Keys \u0026amp; Secrets:\nDeep dive into AWS KMS: key policies, grants, rotation strategies\nEncryption best practices for AWS services (S3, EBS, RDS, DynamoDB)\nManaging sensitive configuration with Secrets Manager and Parameter Store\nData classification and guardrails aligned with compliance and governance needs\nPillar 5 ‚Äî Incident Response AWS Incident Response lifecycle\nWalkthrough of key playbooks:\nCompromised IAM key containment\nS3 public exposure remediation\nEC2 malware detection response steps\nTechniques for snapshot creation, resource isolation, and evidence collection\nAutomated IR workflows using Lambda and Step Functions\nWrap-Up \u0026amp; Q\u0026amp;A Summary of all 5 Security Pillars\nDiscussion on common pitfalls in Vietnamese cloud deployments\nRecommended learning path:\nAWS Security Specialty\nAWS Solutions Architect Professional\nKey Takeaways Security Design Mindset Security must be built from the foundation, not added later\nConsistent enforcement of least privilege and strong identity controls\nVisibility is essential‚Äîlog everything, monitor continuously\nTechnical Implementation Adopt centralized identity with IAM Identity Center\nUse organization-wide logging and threat detection tools\nApply network segmentation and layered protection for workloads\nImplement encryption, key management, and secret rotation systematically\nOperational Excellence Build repeatable incident response playbooks\nAutomate detection and remediation where possible\nEstablish governance practices across multi-account AWS environments\nApplying to Work Review and refactor existing IAM structure following modern IAM patterns\nIntroduce organization-level CloudTrail and centralized logging\nStrengthen infrastructure controls with VPC segmentation + WAF/Shield\nImplement encryption standards and secret rotation policies\nBuild IR playbooks and integrate automation into response workflows\nEvent Experience Attending this workshop provided a structured, comprehensive, and practical understanding of AWS cloud security. Key reflections include:\nLearning from highly skilled speakers In-depth guidance from AWS security specialists\nReal-world examples of cloud security incidents in Vietnam\nHands-on demonstrations Practical IAM policy simulation\nStep-by-step examples of threat detection and IR automation\nStrategic mindset shift Understanding that security is not only technical‚Äîit requires governance, culture, and continuous improvement\nNetworking opportunities Engaging discussions with AWS experts and peers on real security challenges faced by enterprises\nOverall, this workshop strengthened both my technical skills and strategic understanding of cloud security, helping me design more secure, resilient, and compliant architectures.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.1-workshop-overview/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "VPC endpoints VPC endpoints are virtual devices. They are horizontally scaled, redundant, and highly available VPC components. They allow communication between your compute resources and AWS services without imposing availability risks. Compute resources running in VPC can access Amazon S3 using a Gateway endpoint. PrivateLink interface endpoints can be used by compute resources running in VPC or on-premises. Workshop overview In this workshop, you will use two VPCs.\n\u0026ldquo;VPC Cloud\u0026rdquo; is for cloud resources such as a Gateway endpoint and an EC2 instance to test with. \u0026ldquo;VPC On-Prem\u0026rdquo; simulates an on-premises environment such as a factory or corporate datacenter. An EC2 instance running strongSwan VPN software has been deployed in \u0026ldquo;VPC On-prem\u0026rdquo; and automatically configured to establish a Site-to-Site VPN tunnel with AWS Transit Gateway. This VPN simulates connectivity from an on-premises location to the AWS cloud. To minimize costs, only one VPN instance is provisioned to support this workshop. When planning VPN connectivity for your production workloads, AWS recommends using multiple VPN devices for high availability. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Prepare the environment",
	"tags": [],
	"description": "",
	"content": "To prepare for this part of the workshop you will need to:\nDeploying a CloudFormation stack Modifying a VPC route table. These components work together to simulate on-premises DNS forwarding and name resolution.\nDeploy the CloudFormation stack The CloudFormation template will create additional services to support an on-premises simulation:\nOne Route 53 Private Hosted Zone that hosts Alias records for the PrivateLink S3 endpoint One Route 53 Inbound Resolver endpoint that enables \u0026ldquo;VPC Cloud\u0026rdquo; to resolve inbound DNS resolution requests to the Private Hosted Zone One Route 53 Outbound Resolver endpoint that enables \u0026ldquo;VPC On-prem\u0026rdquo; to forward DNS requests for S3 to \u0026ldquo;VPC Cloud\u0026rdquo; Click the following link to open the AWS CloudFormation console. The required template will be pre-loaded into the menu. Accept all default and click Create stack. It may take a few minutes for stack deployment to complete. You can continue with the next step without waiting for the deployemnt to finish.\nUpdate on-premise private route table This workshop uses a strongSwan VPN running on an EC2 instance to simulate connectivty between an on-premises datacenter and the AWS cloud. Most of the required components are provisioned before your start. To finalize the VPN configuration, you will modify the \u0026ldquo;VPC On-prem\u0026rdquo; routing table to direct traffic destined for the cloud to the strongSwan VPN instance.\nOpen the Amazon EC2 console\nSelect the instance named infra-vpngw-test. From the Details tab, copy the Instance ID and paste this into your text editor\nNavigate to the VPC menu by using the Search box at the top of the browser window.\nClick on Route Tables, select the RT Private On-prem route table, select the Routes tab, and click Edit Routes.\nClick Add route. Destination: your Cloud VPC cidr range Target: ID of your infra-vpngw-test instance (you saved in your editor at step 1) Click Save changes "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 1 Objectives: Gain an overview of AWS fundamentals and get familiar with both the Management Console and the AWS CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 09/08/2025 09/12/2025 2 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 09/08/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ 3 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 09/08/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 09/08/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ 5 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 09/08/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ Week 1 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 2 Objectives: Finish Module 01 of the First Cloud Journey. Learn how AWS cost optimization works. Complete all Module 01 labs. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 09/15/2025 09/19/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 09/15/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 09/15/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 09/15/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 09/15/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ Week 2 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 3 Objectives: Start Module 02 ‚Äì Networking. Understand VPC, subnet, route table, IGW, NAT Gateway. Know the difference between Security Groups and NACLs. Complete the basic VPC labs. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 09/22/2025 09/26/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 09/22/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 09/22/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 09/22/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 09/22/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ Week 3 Achievements: Learned the difference between SG and NACL clearly. Finished all basic VPC labs for Module 02. Understood the basic blocks of AWS networking. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 4 Objectives: Practice Hybrid DNS with Route 53 Resolver. Continue Module 02 labs. Launch EC2 instances inside VPC subnets. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 09/29/2025 10/03/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 09/29/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 09/29/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 09/29/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 09/29/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ Week 4 Achievements: Built a full VPC networking environment. Launched EC2 in both public and private subnets. Worked with Route53 Resolver for hybrid DNS. Completed all remaining Module 02 basics. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 5 Objectives: Learn the difference between VPC Peering and Transit Gateway. Practice connecting multiple VPCs. Complete Module 02 advanced labs. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 10/06/2025 10/10/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 10/06/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 10/06/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 10/06/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 10/06/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ Week 5 Achievements: Learned how to connect VPCs using peering and TGW. Successfully tested traffic between VPCs. Completed all advanced networking labs. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 6 Objectives: Start Module 03 ‚Äì Compute. Learn EC2 basics: AMI, Instance Type, EBS. Do backup \u0026amp; Storage Gateway labs. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 10/13/2025 10/17/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 10/13/2025 10/17/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 10/13/2025 10/17/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 10/13/2025 10/17/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 10/13/2025 10/17/2025 https://cloudjourney.awsstudygroup.com/ Week 6 Achievements: Launched EC2, created AMI and snapshots. Completed backup \u0026amp; restore labs. Understood how EBS, metadata, and User Data work. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 7 Objectives: Learn everything about S3. Build a static website on S3. Practice CloudFront, versioning, replication. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 10/20/2025 10/24/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 10/20/2025 10/24/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 10/20/2025 10/24/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 10/20/2025 10/24/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 10/20/2025 10/24/2025 https://cloudjourney.awsstudygroup.com/ Week 7 Achievements: Successfully hosted a website on S3. Configured CloudFront distribution. Learned versioning, object movement, and multi-region replication. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 8 Objectives: Understand AWS security fundamentals. Practice IAM: users, roles, policies. Work with Organizations, Identity Center, and KMS. Complete major security labs. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 10/27/2025 10/31/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 10/27/2025 10/31/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 10/27/2025 10/31/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 10/27/2025 10/31/2025 https://cloudjourney.awsstudygroup.com/ 6 - Midterm test: + Midterm test + Connect via SSH + Attach an EBS volume 31/10/2025 10/31/2025 https://cloudjourney.awsstudygroup.com/ Week 8 Achievements: Know how AWS security model works. Created users, roles, and policies. Used KMS for encryption. Completed the main security labs. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 9 Objectives: Learn RDS, Aurora, DynamoDB, ElastiCache. Practice building databases on AWS. Do Migration Service labs. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 11/03/2025 11/07/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 11/03/2025 11/07/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 11/03/2025 11/07/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 11/03/2025 11/07/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 11/03/2025 11/07/2025 https://cloudjourney.awsstudygroup.com/ Week 9 Achievements: Created RDS and connected it to EC2. Understood DB subnet groups, SGs, and backup/restore. Completed migration labs from MSSQL/Oracle to Aurora. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "On this page, you will need to introduce your worklog. How did you complete it? How many weeks did you take to complete the program? What did you do in those weeks?\nTypically, and as a standard, a worklog is carried out over about 3 months (throughout the internship period) with weekly contents as follows:\nWeek 1: Getting familiar with AWS and basic AWS services\nWeek 2: Doing task A\u0026hellip;\nWeek 3: Doing task B\u0026hellip;\nWeek 4: Doing task C\u0026hellip;\nWeek 5: Doing task D\u0026hellip;\nWeek 6: Doing task E\u0026hellip;\nWeek 7: Doing task G\u0026hellip;\nWeek 8: Doing task H\u0026hellip;\nWeek 9: Doing task I\u0026hellip;\nWeek 10: Doing task L\u0026hellip;\nWeek 11: Doing task M\u0026hellip;\nWeek 12: Doing task N\u0026hellip;\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "AWS Security Scan Project ‚Äì Project Plan [Team DevSecOps FCJ] ‚Äì [FPT University / Internship Program] ‚Äì [AWS Security Scan Project] Date: 2025-10-11\nTABLE OF CONTENTS 1.BACKGROUND AND MOTIVATION\n1.1 EXECUTIVE SUMMARY\n1.2 PROJECT SUCCESS CRITERIA\n1.3 ASSUMPTIONS\n2.SOLUTION ARCHITECTURE / ARCHITECTURAL DIAGRAM\n2.1 TECHNICAL ARCHITECTURE DIAGRAM\n2.2 TECHNICAL PLAN\n2.3 PROJECT PLAN\n2.4 SECURITY CONSIDERATIONS\n3.ACTIVITIES AND DELIVERABLES\n3.1 ACTIVITIES AND DELIVERABLES\n3.2 OUT OF SCOPE\n3.3 PATH TO PRODUCTION\n4.EXPECTED AWS COST BREAKDOWN BY SERVICES\n5.TEAM\n6.RESOURCES \u0026amp; COST ESTIMATES\n7.ACCEPTANCE\n1. BACKGROUND AND MOTIVATION 1.1 EXECUTIVE SUMMARY The AWS Security Scan Project aims to automate the security inspection process across the software development lifecycle by integrating AWS services such as CodePipeline, CodeBuild, CodeGuru Reviewer, and AWS Security Hub. This initiative enhances the security posture of continuous integration and deployment pipelines by embedding automated vulnerability scanning, AI-powered code analysis, and centralized incident monitoring. Use cases include:\nContinuous integration with built-in security validation.\nAutomated alerts and compliance reporting.\nReal-time visibility into vulnerabilities and code quality.\nPartner services focus on designing, implementing, and optimizing a DevSecOps pipeline that ensures secure, compliant, and efficient software delivery.\n1.2 PROJECT SUCCESS CRITERIA ‚â•95% of code commits pass automated security scans before deployment.\nReal-time alerts are sent within 2 minutes of anomaly detection.\nSecurity Hub compliance score ‚â•90%.\nSuccessful integration between CodePipeline, CodeBuild, and Security Hub with zero manual intervention.\n1.3 ASSUMPTIONS All AWS accounts are pre-configured with IAM roles and permissions for CodePipeline and CodeBuild.\nGitLab repository access and webhooks are enabled.\nSecurity tools (e.g., Trivy, Bandit, SonarQube) are available in CodeBuild environment.\nThe organization follows AWS Well-Architected and Security best practices.\n2. SOLUTION ARCHITECTURE / ARCHITECTURAL DIAGRAM 2.1 TECHNICAL ARCHITECTURE DIAGRAM The proposed solution integrates multiple AWS services for CI/CD, automated security analysis, and monitoring. It includes components for source control (GitLab), build and test automation (CodeBuild), pipeline orchestration (CodePipeline), AI-based code review (CodeGuru Reviewer), and centralized alerting (Security Hub + SNS).\nTools used: GitLab\nAWS CodePipeline\nAWS CodeBuild\nAWS CodeGuru Reviewer\nAWS Security Hub, GuardDuty, Detective\nSonarQube, Trivy, Bandit\n2.2 TECHNICAL PLAN The partner will develop buildspec scripts in YAML for CodeBuild to automate:\nSource code scanning (Trivy, Bandit)\nStatic code analysis (CodeGuru Reviewer)\nBuild packaging and deployment triggers\nAll deployments will be version-controlled via GitLab CI triggers. Configuration files will follow Infrastructure as Code principles using AWS CloudFormation.\n2.3 PROJECT PLAN The team will adopt Agile Scrum methodology over 4 sprints (2 weeks each). Stakeholders will participate in Sprint Reviews and Retrospectives.\nRoles and responsibilities:\nDevOps Engineer: CI/CD pipeline setup\nSecurity Engineer: Security integration and analysis\nProject Lead: Coordination, reporting, documentation\nWeekly sync-up meetings will be held via Slack and AWS Chime.\n2.4 SECURITY CONSIDERATIONS Access ‚Äì IAM least privilege, MFA for admin accounts\nInfrastructure ‚Äì Private subnets for build agents\nData ‚Äì S3 encryption (SSE-KMS), CodeBuild log encryption\nDetection ‚Äì GuardDuty and Security Hub continuous monitoring\nIncident Management ‚Äì SNS notifications and CloudWatch alarms for anomalies\n3. ACTIVITIES AND DELIVERABLES 3.1 ACTIVITIES AND DELIVERABLES Project Phase Timeline Activities Deliverables/Milestones Total Man-days Assessment Week 1‚Äì2 Analyze existing CI/CD Report \u0026amp; Architecture Design 5 Setup base infrastructure Week 3‚Äì4 Create CodePipeline \u0026amp; CodeBuild Pipeline Deployed 7 Integrate Security Tools Week 5‚Äì6 Add SonarQube, Trivy, Bandit Security Scan Active 6 Monitoring Setup Week 7 Connect Security Hub, CloudWatch Alert System Operational 4 Testing \u0026amp; Go-Live Week 8 Final testing, documentation Go-Live Report 3 Handover Week 9 Knowledge transfer Final Project Handover 2 3.2 OUT OF SCOPE On-premises application security scanning\nThird-party compliance frameworks beyond AWS tools\nNon-AWS CI/CD environments\n3.3 PATH TO PRODUCTION The Proof-of-Concept focuses on AWS-native DevSecOps integration. For production deployment, additional steps such as multi-account security setup, network isolation, and automated patching will be required.\n4. EXPECTED AWS COST BREAKDOWN BY SERVICES Service Description Estimated Monthly Cost (USD) CodePipeline Orchestration 10 CodeBuild Build + Scan 30 CodeGuru Reviewer Code analysis 25 Security Hub Aggregation + Alerts 15 CloudWatch Logs + Metrics 10 S3 Artifact storage 5 SNS Notifications 5 Total (approx.) 100 USD/month 5. TEAM Name Student ID Email / Contact L√™ C√¥ng C·∫£nh SE183750 canhlcse183750@fpt.edu.vn Ph√πng Gia ƒê·ª©c SE183187 ducpgse183187@fpt.edu.vn V≈© Nguy·ªÖn B√¨nh SE193185 vunguyenbinh25@gmail.com L√™ Minh D∆∞∆°ng SE184079 duonglmse184079@fpt.edu.vn Nguy·ªÖn Phi Duy SE180529 duynpse180529@fpt.edu.vn 6. RESOURCES \u0026amp; COST ESTIMATES Resource Responsibility Rate (USD/hr) Total Hours Cost (USD) Solution Architect Design \u0026amp; Review 60 40 2400 DevOps Engineer Pipeline Implementation 45 60 2700 Security Engineer Tool Integration 50 50 2500 Total 150 7600 7. ACCEPTANCE Upon completion of each phase, the provider will submit deliverables to the customer with an Acceptance Form. The customer will review within 8 business days and provide either:\nWritten acceptance confirmation, or\nRejection notice with feedback.\nIf no response is received within the acceptance period, the deliverable is deemed accepted.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Winter 2024 SOC 1 Report Now Available with 183 Services in Scope Written by Paul Hong, Gabby Iem, Michael Murphy, Nathan Samuel, Tushar Jain, and Ryan Wilks ‚Äî March 26, 2025\nAWS is pleased to announce that the System and Organization Controls (SOC) 1 ‚Äì Winter 2024 Report is now officially available. This year‚Äôs report covers 183 AWS services, assessed over a full 12-month period from January 1, 2024 through December 31, 2024, providing customers with comprehensive, year-round assurance.\nThis reflects AWS‚Äôs ongoing commitment to meeting the evolving expectations for cloud service provider assurance and transparency.\nCustomers can download the Winter 2024 SOC 1 Report through AWS Artifact, the self-service portal for accessing AWS compliance reports anytime. Simply sign in to AWS Artifact in the AWS Management Console, or learn more on the Getting Started with AWS Artifact page.\nAWS continues to expand the scope of its compliance programs to help customers meet industry-specific regulatory and architectural requirements. If you have questions or feedback related to SOC compliance, please contact your AWS account team.\nTo explore more about AWS security and compliance programs, visit AWS Compliance Programs. As always, we welcome your questions and feedback ‚Äî feel free to reach out to the AWS Compliance team via the Contact Us page.\nAbout the Authors Paul Hong Paul Hong is a Compliance Program Manager at AWS, overseeing multiple initiatives across security, compliance, and training. He has over 12 years of experience in security assurance.\nPaul holds CISSP, CEH, and CPA certifications and earned a Master‚Äôs in Accounting Information Systems and a Bachelor‚Äôs in Business Administration from James Madison University in Virginia, USA.\nTushar Jain Tushar Jain is a Compliance Program Manager at AWS, leading key initiatives in security and privacy.\nHe holds an MBA from the Indian Institute of Management Shillong and a Bachelor‚Äôs in Electronics \u0026amp; Telecommunications Engineering from Marathwada University.\nWith more than 12 years of experience in information security, he holds the CCSK and CSXF certifications.\nMichael Murphy Michael Murphy serves as a Compliance Program Manager at AWS, where he leads various security and data-protection initiatives.\nHe has 12 years of information security experience and holds both a Master‚Äôs and Bachelor‚Äôs degree in Computer Engineering from Stevens Institute of Technology.\nMichael also maintains multiple industry certifications, including CISSP, CRISC, CISA, and CISM.\nNathan Samuel Nathan Samuel is a Compliance Program Manager at AWS, responsible for several global security and privacy programs.\nHe holds a Bachelor of Commerce from the University of the Witwatersrand in South Africa and brings over 21 years of experience in security assurance.\nNathan‚Äôs certifications include CISA, CRISC, CGEIT, CISM, CDPSE, and Certified Internal Auditor.\nRyan Wilks Ryan Wilks is a Compliance Program Manager at AWS, leading projects across security and privacy domains.\nHe has over 13 years of information security experience, holds a Bachelor of Arts from Rutgers University, and maintains certifications including ITIL, CISM, and CISA.\nGabby Iem Gabby Iem is a Program Manager at AWS supporting various security assurance initiatives.\nShe recently graduated with a Bachelor‚Äôs degree in Business Administration from Chapman University and is actively engaged in security and compliance capability-building programs at AWS.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Create an S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "In this section you will create and test an S3 interface endpoint using the simulated on-premises environment deployed as part of this workshop.\nReturn to the Amazon VPC menu. In the navigation pane, choose Endpoints, then click Create Endpoint.\nIn Create endpoint console:\nName the interface endpoint In Service category, choose aws services In the Search box, type S3 and press Enter. Select the endpoint named com.amazonaws.us-east-1.s3. Ensure that the Type column indicates Interface. For VPC, select VPC Cloud from the drop-down. Make sure to choose \u0026ldquo;VPC Cloud\u0026rdquo; and not \u0026ldquo;VPC On-prem\u0026rdquo;\nExpand Additional settings and ensure that Enable DNS name is not selected (we will use this in the next part of the workshop) Select 2 subnets in the following AZs: us-east-1a and us-east-1b For Security group, choose SGforS3Endpoint: Keep the default policy - full access and click Create endpoint Congratulation on successfully creating S3 interface endpoint. In the next step, we will test the interface endpoint.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.2-prerequiste/",
	"title": "Prerequiste",
	"tags": [],
	"description": "",
	"content": "IAM permissions Add the following IAM permission policy to your user account to deploy and cleanup this workshop.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Provision resources using CloudFormation In this lab, we will use N.Virginia region (us-east-1).\nTo prepare the workshop environment, deploy this CloudFormation Template (click link): PrivateLinkWorkshop . Accept all of the defaults when deploying the template.\nTick 2 acknowledgement boxes Choose Create stack The ClouddFormation deployment requires about 15 minutes to complete.\n2 VPCs have been created 3 EC2s have been created "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Test the Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Create S3 bucket Navigate to S3 management console In the Bucket console, choose Create bucket In the Create bucket console Name the bucket: choose a name that hasn\u0026rsquo;t been given to any bucket globally (hint: lab number and your name) Leave other fields as they are (default) Scroll down and choose Create bucket Successfully create S3 bucket. Connect to EC2 with session manager For this workshop, you will use AWS Session Manager to access several EC2 instances. Session Manager is a fully managed AWS Systems Manager capability that allows you to manage your Amazon EC2 instances and on-premises virtual machines (VMs) through an interactive one-click browser-based shell. Session Manager provides secure and auditable instance management without the need to open inbound ports, maintain bastion hosts, or manage SSH keys.\nFirst cloud journey Lab for indepth understanding of Session manager.\nIn the AWS Management Console, start typing Systems Manager in the quick search box and press Enter: From the Systems Manager menu, find Node Management in the left menu and click Session Manager: Click Start Session, and select the EC2 instance named Test-Gateway-Endpoint. This EC2 instance is already running in \u0026ldquo;VPC Cloud\u0026rdquo; and will be used to test connectivity to Amazon S3 through the Gateway endpoint you just created (s3-gwe).\nSession Manager will open a new browser tab with a shell prompt: sh-4.2 $\nYou have successfully start a session - connect to the EC2 instance in VPC cloud. In the next step, we will create a S3 bucket and a file in it.\nCreate a file and upload to s3 bucket Change to the ssm-user\u0026rsquo;s home directory by typing cd ~ in the CLI Create a new file to use for testing with the command fallocate -l 1G testfile.xyz, which will create a file of 1GB size named \u0026ldquo;testfile.xyz\u0026rdquo;. Upload file to S3 bucket with command aws s3 cp testfile.xyz s3://your-bucket-name. Replace your-bucket-name with the name of S3 bucket that you created earlier. You have successfully uploaded the file to your S3 bucket. You can now terminate the session.\nCheck object in S3 bucket Navigate to S3 console. Click the name of your s3 bucket In the Bucket console, you will see the file you have uploaded to your S3 bucket Section summary Congratulation on completing access to S3 from VPC. In this section, you created a Gateway endpoint for Amazon S3, and used the AWS CLI to upload an object. The upload worked because the Gateway endpoint allowed communication to S3, without needing an Internet Gateway attached to \u0026ldquo;VPC Cloud\u0026rdquo;. This demonstrates the functionality of the Gateway endpoint as a secure path to S3 without traversing the Public Internet.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Work with AWS analytics services. Practice Glue, Athena, Kinesis, and QuickSight. Complete labs 35, 39, and 40. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 11/10/2025 11/14/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 11/10/2025 11/14/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 11/10/2025 11/14/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 11/10/2025 11/14/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 11/10/2025 11/14/2025 https://cloudjourney.awsstudygroup.com/ Week 10 Achievements: Built a basic data pipeline. Learned how Glue, Athena, and QuickSight fit together. Used tags for AWS cost tracking. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Learn CloudShell, SDK usage, and Cloud9. Practice ETL with Glue \u0026amp; DataBrew. Work on end-to-end data pipeline (Lab72). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 11/17/2025 11/21/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 11/17/2025 11/21/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 11/17/2025 11/21/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 11/17/2025 11/21/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 11/17/2025 11/21/2025 https://cloudjourney.awsstudygroup.com/ Week 11 Achievements: Used CloudShell and Cloud9 for development. Practiced data cleaning with DataBrew. Built a multi-step pipeline using Glue, EMR, and Athena. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Finish all remaining labs (Module 72 + 73). Clean up all AWS resources to avoid charges. Summarize everything learned in the Bootcamp. Complete final internship report. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 11/24/2025 11/28/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 11/24/2025 11/28/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 11/24/2025 11/28/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 11/24/2025 11/28/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 11/24/2025 11/28/2025 https://cloudjourney.awsstudygroup.com/ Week 12 Achievements: Completed all Bootcamp modules and labs. Fully cleaned AWS resources to avoid extra charges. Summarized key learnings from cloud, networking, compute, storage, security, database, and analytics. Ready to submit the final internship report. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.3-s3-vpc/",
	"title": "Access S3 from VPC",
	"tags": [],
	"description": "",
	"content": "Using Gateway endpoint In this section, you will create a Gateway eendpoint to access Amazon S3 from an EC2 instance. The Gateway endpoint will allow upload an object to S3 buckets without using the Public Internet. To create an endpoint, you must specify the VPC in which you want to create the endpoint, and the service (in this case, S3) to which you want to establish the connection.\nContent Create gateway endpoint Test gateway endpoint "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Test the Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Get the regional DNS name of S3 interface endpoint From the Amazon VPC menu, choose Endpoints.\nClick the name of newly created endpoint: s3-interface-endpoint. Click details and save the regional DNS name of the endpoint (the first one) to your text-editor for later use.\nConnect to EC2 instance in \u0026ldquo;VPC On-prem\u0026rdquo; Navigate to Session manager by typing \u0026ldquo;session manager\u0026rdquo; in the search box\nClick Start Session, and select the EC2 instance named Test-Interface-Endpoint. This EC2 instance is running in \u0026ldquo;VPC On-prem\u0026rdquo; and will be used to test connectivty to Amazon S3 through the Interface endpoint we just created. Session Manager will open a new browser tab with a shell prompt: sh-4.2 $\nChange to the ssm-user\u0026rsquo;s home directory with command \u0026ldquo;cd ~\u0026rdquo;\nCreate a file named testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file to the same S3 bucket we created in section 3.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; This command requires the \u0026ndash;endpoint-url parameter, because you need to use the endpoint-specific DNS name to access S3 using an Interface endpoint. Do not include the leading \u0026rsquo; * \u0026rsquo; when copying/pasting the regional DNS name. Provide your S3 bucket name created earlier Now the file has been added to your S3 bucket. Let check your S3 bucket in the next step.\nCheck Object in S3 bucket Navigate to S3 console Click Buckets Click the name of your bucket and you will see testfile2.xyz has been added to your bucket "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/3-blogstranslated/",
	"title": "Translated Blogs",
	"tags": [],
	"description": "",
	"content": "This section will list and introduce the blogs you have translated. For example:\nBlog 1 - What Customers Need to Know About Critical Third Parties (CTPs) in the UK The UK Critical Third Parties (CTP) regime establishes a robust framework to oversee third-party services critical to the stability and trust of the financial system. It defines Systemic Third-Party Services (STPS), sets clear expectations for testing, incident management, and regulatory reporting, and aligns with international standards for operational resilience.\nWhile the regime does not impose direct obligations on financial institutions‚Äô customers, it emphasizes accurate reporting and transparency to enable regulators to identify and manage risks effectively. AWS supports this outcomes-based framework and remains committed to helping customers enhance operational resilience through guidance, tools, and cloud-based services.\nOverall, the CTP regime strengthens the UK financial sector by reducing systemic third-party concentration risks and promoting a more resilient, well-managed infrastructure.\nBlog 2 - The SOC 1 Winter 2024 report by AWS The SOC 1 Winter 2024 report by AWS provides comprehensive assurance for 183 services over the full year of 2024, reflecting AWS‚Äôs continued commitment to meeting stringent compliance and security standards. By making the report accessible through AWS Artifact, customers can easily verify AWS‚Äôs compliance status and integrate this information into their own audit and risk management processes.\nAWS continues to expand its compliance programs to support customers across industries, ensuring that security, privacy, and operational requirements are met. The SOC 1 report underscores AWS‚Äôs dedication to transparency, customer trust, and effective governance, enabling organizations to rely on AWS services with confidence.\nBlog 3 - Sharing the vision of a more connected world with AWS IoT AWS IoT continues to drive innovation and deliver tailored, verticalized solutions across industries, enabling customers to achieve specific business outcomes through connected devices, digital twins, smart cities, and connected vehicles. By leveraging a broad suite of cloud and edge services, along with a strong partner ecosystem, AWS simplifies IoT adoption, ensures scalability, and enhances operational efficiency.\nThe IoT strategy at AWS focuses on understanding customer challenges, providing prebuilt solutions, and integrating AI, machine learning, and analytics to unlock data and optimize processes. Across sectors such as industrial, retail, commercial buildings, transportation, and robotics, AWS IoT empowers organizations to increase productivity, improve sustainability, and create new value. Looking forward, AWS remains committed to expanding IoT capabilities, driving cost-effective deployment, and supporting innovation at scale.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.4-s3-onprem/",
	"title": "Access S3 from on-premises",
	"tags": [],
	"description": "",
	"content": "Overview In this section, you will create an Interface endpoint to access Amazon S3 from a simulated on-premises environment. The Interface endpoint will allow you to route to Amazon S3 over a VPN connection from your simulated on-premises environment.\nWhy using Interface endpoint:\nGateway endpoints only work with resources running in the VPC where they are created. Interface endpoints work with resources running in VPC, and also resources running in on-premises environments. Connectivty from your on-premises environment to the cloud can be provided by AWS Site-to-Site VPN or AWS Direct Connect. Interface endpoints allow you to connect to services powered by AWS PrivateLink. These services include some AWS services, services hosted by other AWS customers and partners in their own VPCs (referred to as PrivateLink Endpoint Services), and supported AWS Marketplace Partner services. For this workshop, we will focus on connecting to Amazon S3. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/4-eventparticipated/",
	"title": "Events Participated",
	"tags": [],
	"description": "",
	"content": "During my internship, I participated in three events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: AWS Cloud Mastery Series #1\nDate \u0026amp; Time: 08:00, November 15, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: AWS Cloud Mastery Series #2\nDate \u0026amp; Time: 08:30, November 17, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: AWS Cloud Mastery Series #3\nDate \u0026amp; Time: 08:30, November 25, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "On-premises DNS Simulation",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoints have a fixed IP address in each Availability Zone where they are deployed, for the life of the endpoint (until it is deleted). These IP addresses are attached to Elastic Network Interfaces (ENIs). AWS recommends using DNS to resolve the IP addresses for endpoints so that downstream applications use the latest IP addresses when ENIs are added to new AZs, or deleted over time.\nIn this section, you will create a forwarding rule to send DNS resolution requests from a simulated on-premises environment to a Route 53 Private Hosted Zone. This section leverages the infrastructure deployed by CloudFormation in the Prepare the environment section.\nCreate DNS Alias Records for the Interface endpoint Navigate to the Route 53 management console (Hosted Zones section). The CloudFormation template you deployed in the Prepare the environment section created this Private Hosted Zone. Click on the name of the Private Hosted Zone, s3.us-east-1.amazonaws.com: Create a new record in the Private Hosted Zone: Record name and record type keep default options Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor (you saved when doing section 4.3) Click Add another record, and add a second record using the following values. Click Create records when finished to create both records. Record name: *. Record type: keep default value (type A) Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor The new records appear in the Route 53 console:\nCreate a Resolver Forwarding Rule Route 53 Resolver Forwarding Rules allow you to forward DNS queries from your VPC to other sources for name resolution. Outside of a workshop environment, you might use this feature to forward DNS queries from your VPC to DNS servers running on-premises. In this section, you will simulate an on-premises conditional forwarder by creating a forwarding rule that forwards DNS queries for Amazon S3 to a Private Hosted Zone running in \u0026ldquo;VPC Cloud\u0026rdquo; in-order to resolve the PrivateLink interface endpoint regional DNS name.\nFrom the Route 53 management console, click Inbound endpoints on the left side bar In the Inbound endpoints console, click the ID of the inbound endpoint Copy the two IP addresses listed to your text editor From the Route 53 menu, choose Resolver \u0026gt; Rules, and click Create rule: In the Create rule console: Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: Enter both IP addresses from your text editor (inbound endpoint addresses) and then click Submit You have successfully created resolver forwarding rule.\nTest the on-premises DNS Simulation Connect to Test-Interface-Endpoint EC2 instance with Session manager Test DNS resolution. The dig command will return the IP addresses assigned to the VPC Interface endpoint running in VPC Cloud (your IP\u0026rsquo;s will be different): dig +short s3.us-east-1.amazonaws.com The IP addresses returned are the VPC endpoint IP addresses, NOT the Resolver IP addresses you pasted from your text editor. The IP addresses of the Resolver endpoint and the VPC endpoint look similar because they are all from the VPC Cloud CIDR block.\nNavigate to the VPC menu (Endpoints section), select the S3 Interface endpoint. Click the Subnets tab and verify that the IP addresses returned by Dig match the VPC endpoint: Return to your shell and use the AWS CLI to test listing your S3 buckets: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Terminate your Session Manager session: In this section you created an Interface endpoint for Amazon S3. This endpoint can be reached from on-premises through Site-to-Site VPN or AWS Direct Connect. Route 53 Resolver outbound endpoints simulated forwarding DNS requests from on-premises to a Private Hosted Zone running the cloud. Route 53 inbound Endpoints recieved the resolution request and returned a response containing the IP addresses of the VPC interface endpoint. Using DNS to resolve the endpoint IP addresses provides high availability in-case of an Availability Zone outage.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "When you create an interface or gateway endpoint, you can attach an endpoint policy to it that controls access to the service to which you are connecting. A VPC endpoint policy is an IAM resource policy that you attach to an endpoint. If you do not attach a policy when you create an endpoint, AWS attaches a default policy for you that allows full access to the service through the endpoint.\nYou can create a policy that restricts access to specific S3 buckets only. This is useful if you only want certain S3 Buckets to be accessible through the endpoint.\nIn this section you will create a VPC endpoint policy that restricts access to the S3 bucket specified in the VPC endpoint policy.\nConnect to an EC2 instance and verify connectivity to S3 Start a new AWS Session Manager session on the instance named Test-Gateway-Endpoint. From the session, verify that you can list the contents of the bucket you created in Part 1: Access S3 from VPC: aws s3 ls s3://\\\u0026lt;your-bucket-name\\\u0026gt; The bucket contents include the two 1 GB files uploaded in earlier.\nCreate a new S3 bucket; follow the naming pattern you used in Part 1, but add a \u0026lsquo;-2\u0026rsquo; to the name. Leave other fields as default and click create Successfully create bucket\nNavigate to: Services \u0026gt; VPC \u0026gt; Endpoints, then select the Gateway VPC endpoint you created earlier. Click the Policy tab. Click Edit policy. The default policy allows access to all S3 Buckets through the VPC endpoint.\nIn Edit Policy console, copy \u0026amp; Paste the following policy, then replace yourbucketname-2 with your 2nd bucket name. This policy will allow access through the VPC endpoint to your new bucket, but not any other bucket in Amazon S3. Click Save to apply the policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Successfully customize policy\nFrom your session on the Test-Gateway-Endpoint instance, test access to the S3 bucket you created in Part 1: Access S3 from VPC aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; This command will return an error because access to this bucket is not permitted by your new VPC endpoint policy:\nReturn to your home directory on your EC2 instance cd~ Create a file fallocate -l 1G test-bucket2.xyz Copy file to 2nd bucket aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; This operation succeeds because it is permitted by the VPC endpoint policy.\nThen we test access to the first bucket by copy the file to 1st bucket aws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt; This command will return an error because access to this bucket is not permitted by your new VPC endpoint policy.\nPart 3 Summary: In this section, you created a VPC endpoint policy for Amazon S3, and used the AWS CLI to test the policy. AWS CLI actions targeted to your original S3 bucket failed because you applied a policy that only allowed access to the second bucket you created. AWS CLI actions targeted for your second bucket succeeded because the policy allowed them. These policies can be useful in situations where you need to control access to resources through VPC endpoints.\n"
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Secure Hybrid Access to S3 using VPC Endpoints Overview AWS PrivateLink provides private connectivity to AWS services from VPCs and your on-premises networks, without exposing your traffic to the Public Internet.\nIn this lab, you will learn how to create, configure, and test VPC endpoints that enable your workloads to reach AWS services without traversing the Public Internet.\nYou will create two types of endpoints to access Amazon S3: a Gateway VPC endpoint, and an Interface VPC endpoint. These two types of VPC endpoints offer different benefits depending on if you are accessing Amazon S3 from the cloud or your on-premises location\nGateway - Create a gateway endpoint to send traffic to Amazon S3 or DynamoDB using private IP addresses.You route traffic from your VPC to the gateway endpoint using route tables. Interface - Create an interface endpoint to send traffic to endpoint services that use a Network Load Balancer to distribute traffic. Traffic destined for the endpoint service is resolved using DNS. Content Workshop overview Prerequiste Access S3 from VPC Access S3 from On-premises VPC Endpoint Policies (Bonus) Clean up "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/5-workshop/5.6-cleanup/",
	"title": "Clean up",
	"tags": [],
	"description": "",
	"content": "Congratulations on completing this workshop! In this workshop, you learned architecture patterns for accessing Amazon S3 without using the Public Internet.\nBy creating a gateway endpoint, you enabled direct communication between EC2 resources and Amazon S3, without traversing an Internet Gateway. By creating an interface endpoint you extended S3 connectivity to resources running in your on-premises data center via AWS Site-to-Site VPN or Direct Connect. clean up Navigate to Hosted Zones on the left side of Route 53 console. Click the name of s3.us-east-1.amazonaws.com zone. Click Delete and confirm deletion by typing delete. Disassociate the Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. Open the CloudFormation console and delete the two CloudFormation Stacks that you created for this lab: PLOnpremSetup PLCloudSetup Delete S3 buckets Open S3 console Choose the bucket we created for the lab, click and confirm empty. Click delete and confirm delete. "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/6-self-evaluation/",
	"title": "Self-Assessment",
	"tags": [],
	"description": "",
	"content": "During my internship at [Company/Organization Name] from [start date] to [end date], I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI participated in [briefly describe the main project or task], through which I improved my skills in [list skills: programming, analysis, reporting, communication, etc.].\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ‚òê ‚úÖ ‚òê 2 Ability to learn Ability to absorb new knowledge and learn quickly ‚òê ‚úÖ ‚òê 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ‚úÖ ‚òê ‚òê 4 Sense of responsibility Completing tasks on time and ensuring quality ‚úÖ ‚òê ‚òê 5 Discipline Adhering to schedules, rules, and work processes ‚òê ‚òê ‚úÖ 6 Progressive mindset Willingness to receive feedback and improve oneself ‚òê ‚úÖ ‚òê 7 Communication Presenting ideas and reporting work clearly ‚òê ‚úÖ ‚òê 8 Teamwork Working effectively with colleagues and participating in teams ‚úÖ ‚òê ‚òê 9 Professional conduct Respecting colleagues, partners, and the work environment ‚úÖ ‚òê ‚òê 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ‚òê ‚úÖ ‚òê 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ‚úÖ ‚òê ‚òê 12 Overall General evaluation of the entire internship period ‚òê ‚úÖ ‚òê Needs Improvement Strengthen discipline and strictly comply with the rules and regulations of the company or any organization Improve problem-solving thinking Enhance communication skills in both daily interactions and professional contexts, including handling situations effectively "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/7-feedback/",
	"title": "Sharing and Feedback",
	"tags": [],
	"description": "",
	"content": "Overall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don‚Äôt understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company provides an internship allowance and offers flexible working hours when needed. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What did you find most satisfying during your internship? What do you think the company should improve for future interns? If recommending to a friend, would you suggest they intern here? Why or why not? Suggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? Would you like to continue this program in the future? Any other comments (free sharing): "
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://github.com/VuNguyenBinh/aws-intern-report/en/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]