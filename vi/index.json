[
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "DevSecOps Pipeline Overview (GitLab → AWS) Mục tiêu pipeline: Tự động hóa toàn bộ quy trình build – quét bảo mật – thông báo lỗi. Phát hiện sớm bug, lỗ hổng bảo mật ngay khi dev commit code. Tạo vòng lặp DevSecOps khép kín: Commit → Scan → Notify → Fix → Commit lại. Tóm tắt luồng: Dev commit code vào GitLab (nhánh main). AWS CodePipeline nhận sự kiện và kích hoạt pipeline. CodeBuild chạy Sonar Scanner để phân tích mã nguồn. SonarQube trên EC2 nhận kết quả quét từ Scanner. SonarQube gửi Webhook → API Gateway → Lambda. Lambda xử lý dữ liệu → gửi thông báo qua SNS → email dev. Dev nhận báo cáo lỗi → Fix → Commit lại → quay lại vòng lặp. Hệ thống đảm bảo: Tự động hóa kiểm thử bảo mật. Cải thiện chất lượng mã nguồn. Giảm rủi ro bảo mật và lỗi logic. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm công việc A\u0026hellip;\nTuần 3: Làm công việc B\u0026hellip;\nTuần 4: Làm công việc C\u0026hellip;\nTuần 5: Làm công việc D\u0026hellip;\nTuần 6: Làm công việc E\u0026hellip;\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Workshop Report: \u0026ldquo;AI/ML/GenAI on AWS\u0026rdquo; Workshop Goals Nắm được bức tranh tổng quan về AI/ML và hệ sinh thái dịch vụ AWS tại Việt Nam Tìm hiểu quy trình xây dựng mô hình machine learning end-to-end với Amazon SageMaker Khám phá khả năng Generative AI trên Amazon Bedrock Hiểu và thực hành các kỹ thuật prompt engineering và RAG (Retrieval-Augmented Generation) Xây dựng các bài toán AI/ML thực tế dựa trên dịch vụ AWS Event Information Địa điểm: Văn phòng AWS Vietnam Thời gian: 8:30 AM – 12:00 PM, Thứ Bảy, ngày 15/11/2025 Instructors \u0026amp; Organizing Team Giảng viên:\nLâm Tuấn Kiệt – Senior DevOps Engineer, FPT Software Phụ trách phần tổng quan Amazon SageMaker và các dịch vụ ML trên AWS Đinh Lê Hoàng Anh – Cloud Engineer Trainee, FCAJ, Swinburne University of Technology Trình bày về Amazon Bedrock và hệ sinh thái AWS AI/ML Danh Hoàng Hiếu Nghị – Fresher AI Engineer, Renova Cloud Hướng dẫn phần Amazon Bedrock Agent Core, demo live và hỗ trợ thực hành Đơn vị điều phối:\nAWS Vietnam Community Team Đội ngũ chương trình FCJ (First Cloud Journey) Agenda Chi Tiết 8:30 – 9:00 AM: Đón tiếp \u0026amp; Giới thiệu chung Check-in người tham dự, giao lưu ban đầu Giới thiệu mục tiêu của workshop và nội dung chính trong buổi Hoạt động ice-breaker làm quen Lướt qua bối cảnh và xu hướng AI/ML tại Việt Nam 9:00 – 10:30 AM: Tổng quan AWS AI/ML – Amazon SageMaker Amazon SageMaker – Nền tảng ML end-to-end\nChuẩn bị và xử lý dữ liệu:\nSử dụng SageMaker Data Wrangler để xử lý, làm sạch dữ liệu Dùng Ground Truth cho việc gán nhãn và annotate dữ liệu Quản lý feature tập trung với Feature Store Huấn luyện, tinh chỉnh và triển khai mô hình:\nTận dụng các built-in algorithm hoặc script custom Tối ưu mô hình bằng hyperparameter tuning Nhiều lựa chọn triển khai: real-time, batch, serverless inference Thử nghiệm A/B và multi-model endpoints cho so sánh mô hình Tính năng MLOps tích hợp:\nSageMaker Pipelines để tự động hóa pipeline ML Model Registry hỗ trợ quản lý version và governance Model Monitor theo dõi data drift, chất lượng mô hình Kết hợp với CI/CD để triển khai mô hình liên tục Demo trực quan – SageMaker Studio:\nTạo và sử dụng notebook instance Train một mô hình ML mẫu Deploy endpoint và gọi thử dự đoán 10:30 – 10:45 AM: Nghỉ giải lao Nghỉ ngơi, dùng nước/coffee Trao đổi tự do, hỏi nhanh với các anh/chị AWS 10:45 AM – 12:00 PM: Generative AI với Amazon Bedrock \u0026amp; AWS AI/ML Tổng quan các dịch vụ AI/ML trên AWS\nAmazon Rekognition: Phân tích hình ảnh/video, nhận diện đối tượng Amazon Translate: Dịch ngôn ngữ tự động với mô hình NMT Amazon Textract: Trích xuất text và dữ liệu từ tài liệu, form Amazon Transcribe: Chuyển giọng nói thành văn bản Amazon Polly: TTS – đọc văn bản với giọng tự nhiên Amazon Comprehend: Xử lý ngôn ngữ tự nhiên, phân tích cảm xúc/chủ đề Amazon Kendra: Search engine thông minh dựa trên ML Amazon Lookout: Phát hiện bất thường từ dữ liệu vận hành Amazon Personalize: Gợi ý cá nhân hóa dựa trên ML Foundation Models: Claude, Llama, Titan\nSo sánh và cách chọn mô hình: Claude (Anthropic): Mạnh ở hội thoại, lý luận phức tạp Llama (Meta): Linh hoạt, phù hợp tùy biến, mã nguồn mở Titan (Amazon): Tích hợp sâu với AWS, tối ưu cho hệ sinh thái AWS Cách cân nhắc chọn model theo bài toán thực tế Prompt Engineering\nCác nguyên tắc prompt hiệu quả:\nViết prompt rõ ràng, đưa đủ bối cảnh Sử dụng ví dụ (few-shot) để định hướng output Dùng chain-of-thought cho các tác vụ phức tạp Đặt vai trò cho model (persona, role-based prompting) Kỹ thuật nâng cao:\nĐiều chỉnh temperature, max tokens Phân biệt giữa system prompt và user prompt Dùng template để tái sử dụng prompt cho nhiều bài toán Retrieval-Augmented Generation (RAG)\nKiến trúc RAG:\nDùng vector database và embeddings để biểu diễn tài liệu Semantic search để tìm ngữ nghĩa gần nhất Đưa context tài liệu tìm được vào prompt LLM Tích hợp Knowledge Base:\nSử dụng Amazon Bedrock Knowledge Bases Lưu trữ tài liệu/tri thức trên Amazon S3 Kết nối tới nhiều nguồn dữ liệu (S3, DB, API) Thiết kế cách chunk tài liệu và gắn metadata Cấu hình bucket policy và phân quyền truy cập S3 an toàn Amazon Bedrock Agent Core\nXây dựng AI Agent:\nBedrock Agent Core giúp điều phối các bước tác vụ Hỗ trợ multi-step reasoning và lập kế hoạch hành động Cấu hình action groups, tích hợp API bên ngoài Quản lý memory và trạng thái hội thoại Tích hợp với công cụ bên ngoài:\nGọi AWS Lambda để xử lý logic tùy biến Sử dụng Lambda cho xử lý dữ liệu thời gian thực Kết nối API của hệ thống khác thông qua Lambda Thực thi truy vấn DB, lấy dữ liệu để agent sử dụng Mô hình serverless với Lambda + Bedrock giúp dễ mở rộng và quản lý Guardrails: An Toàn \u0026amp; Lọc Nội Dung\nThiết lập lọc nội dung nhạy cảm, độc hại Ẩn hoặc xử lý PII (thông tin nhận dạng cá nhân) Giới hạn chủ đề, block các topic không được phép Tùy biến guardrails theo yêu cầu tuân thủ của doanh nghiệp Demo: Xây dựng Chatbot Generative AI với Bedrock\nCấu hình quyền truy cập foundation model trong Bedrock Tạo chatbot đơn giản với prompt engineering Bổ sung RAG bằng Knowledge Bases Thêm guardrails đảm bảo phản hồi an toàn Thử nghiệm, điều chỉnh prompt và luồng xử lý Những Điều Rút Ra Được Về Amazon SageMaker Nền tảng ML đầy đủ: Từ chuẩn bị dữ liệu, training, đến deploy đều có tool hỗ trợ Hỗ trợ MLOps: Pipelines, Model Registry và Monitor giúp quy trình ML ổn định hơn Dễ mở rộng: Từ test nhỏ trong notebook đến production quy mô lớn Tối ưu chi phí: Có spot, serverless inference và nhiều lựa chọn cấu hình tài nguyên Về Generative AI với Bedrock Nhiều lựa chọn model: Có thể thử và chuyển đổi giữa các foundation model mà không cần tự quản lý hạ tầng Prompt engineering là chìa khóa: Output tốt hay không phụ thuộc rất nhiều vào prompt RAG: Giải quyết bài toán đưa dữ liệu nội bộ vào LLM mà vẫn đảm bảo cập nhật và kiểm soát được Guardrails: Cực quan trọng để triển khai AI một cách an toàn, đúng quy định Agent: Cho phép xây dựng các luồng xử lý phức tạp, nhiều bước thay vì chỉ chat Q\u0026amp;A đơn giản Ứng Dụng Thực Tế Bắt đầu từ use case cụ thể: Không làm AI chung chung mà gắn với bài toán thật Prototype nhanh: Dùng SageMaker Studio để thử nghiệm trước khi đầu tư lớn Tận dụng foundation models: Thử model sẵn có rồi mới tính đến training custom nếu cần Luôn có guardrails: Đặc biệt với sản phẩm tiếp xúc người dùng cuối Theo dõi và tối ưu liên tục: Về chất lượng mô hình lẫn chi phí vận hành Cách Áp Dụng Vào Công Việc Thử dựng các pipeline đơn giản trên SageMaker Studio Xây dựng thử một RAG chatbot dùng Bedrock + S3 làm knowledge base Tập trung luyện prompt engineering trên nhiều loại foundation model khác nhau Thiết kế MLOps pipeline bằng SageMaker Pipelines cho các bài toán ML nội bộ Nghĩ tới việc dùng Bedrock Agents để tự động hóa một số quy trình lặp lại Kết hợp Guardrails để đáp ứng yêu cầu bảo mật và tuân thủ Ghi chép lại kinh nghiệm, chia sẻ cho team để cùng chuẩn hóa cách làm Trải Nghiệm Tại Sự Kiện Tham gia \u0026ldquo;AI/ML/GenAI on AWS Workshop\u0026rdquo; tại văn phòng AWS Vietnam mang lại cảm giác khá “đã” vì vừa có phần lý thuyết, vừa có phần demo thực tế:\nHọc Từ Chuyên Gia AWS Các anh chị chuyên gia AWS giải thích khá dễ hiểu về cách SageMaker vận hành end-to-end Phần demo Bedrock cho thấy rõ việc build một ứng dụng GenAI trên AWS đơn giản hơn mình tưởng Nhiều ví dụ thực tế từ doanh nghiệp tại Việt Nam, giúp hình dung cách áp dụng vào bối cảnh local Được gợi ý cách chọn đúng dịch vụ/ mô hình cho từng loại bài toán Demo \u0026amp; Thực Hành Thấy trực tiếp quy trình từ dữ liệu → train → deploy một mô hình trên SageMaker Studio Hiểu được luồng build một GenAI app với Bedrock mà không phải lo phần hạ tầng bên dưới Áp dụng ngay các kỹ thuật prompt engineering vào ví dụ thực tế RAG demo giúp thấy rõ khác biệt giữa “LLM nói chung chung” và “LLM có kiến thức nội bộ” Agent demo cho thấy tiềm năng tự động hóa nhiều công việc phức tạp Hiểu Rõ Hơn Về AI/ML Hiện Nay Có cái nhìn rõ hơn về sự khác biệt giữa ML truyền thống và Generative AI Biết khi nào nên chọn SageMaker, khi nào nên ưu tiên Bedrock Nắm được tại sao MLOps là yếu tố bắt buộc nếu muốn đưa ML vào production Kết Nối Cộng Đồng Làm quen thêm nhiều bạn cũng đang bắt đầu với AI/ML trên AWS Trao đổi khá nhiều về khó khăn khi triển khai thực tế (dữ liệu, chi phí, nhân sự, …) Có thêm kênh liên lạc với cộng đồng và các anh chị AWS để hỏi khi cần Những Ghi Chú Quan Trọng Foundation models giúp tiết kiệm rất nhiều thời gian và nguồn lực ban đầu Prompt tốt có thể thay đổi hẳn chất lượng output mà không cần động đến kiến trúc model RAG là một hướng cực kỳ hữu ích khi muốn AI hiểu tài liệu nội bộ Guardrails không chỉ là “nice-to-have” mà gần như là bắt buộc SageMaker là nền tảng phù hợp nếu muốn làm bài bản và đi dài hơi với ML Bước Tiếp Theo Dùng thời gian rảnh để thử nghiệm thêm trên SageMaker Studio Làm một prototype RAG nhỏ dùng Bedrock + S3 cho tài liệu nội bộ Thử nhiều kiểu prompt khác nhau cho cùng một bài toán để rút kinh nghiệm Nghiên cứu sâu hơn về Bedrock Agents cho các use case workflow phức tạp Bắt đầu chuẩn hóa cách log, monitor và deploy mô hình giống MLOps chuẩn Tiếp tục cập nhật kiến thức qua cộng đồng AWS AI/ML và các buổi meetup sau này Event Pictures Nhìn chung, workshop này cung cấp giới thiệu toàn diện về dịch vụ AWS AI/ML, từ machine learning truyền thống với SageMaker đến Generative AI tiên tiến với Bedrock. Các trình diễn thực hành và hướng dẫn chuyên gia làm cho các khái niệm phức tạp trở nên dễ tiếp cận và có thể áp dụng ngay lập tức. Điểm chính rút ra là AWS cung cấp một hệ sinh thái hoàn chỉnh để xây dựng, triển khai và mở rộng ứng dụng AI/ML, giúp việc đưa đổi mới AI vào production dễ dàng hơn bao giờ hết.\n"
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/3-blogstranslated/3.1-blog1/",
	"title": "Sử dụng Large Language Models trên Amazon Bedrock cho Thực thi Tác vụ Đa bước",
	"tags": [],
	"description": "",
	"content": "Trong bài viết này, chúng ta sẽ tìm hiểu cách sử dụng Large Language Models (LLMs) trên Amazon Bedrock để thực hiện các tác vụ phân tích gồm nhiều bước, cần suy luận và sử dụng API bên ngoài. Mục tiêu là biến các truy vấn phức tạp thành chuỗi các bước Plan → Execute rõ ràng, dễ kiểm soát và dễ mở rộng.\n1. Bối cảnh Các câu hỏi phân tích dữ liệu trong doanh nghiệp thường phức tạp, ví dụ:\n“Thời gian nằm viện trung bình của bệnh nhân mắc bệnh X tại các bệnh viện khác nhau là bao lâu?” “Xu hướng kê đơn thuốc Y thay đổi như thế nào giữa các khu vực?” Trước đây, việc trả lời yêu cầu:\nChuyên gia BI Kỹ sư dữ liệu Quy trình nhiều bước, tốn thời gian Với LLM + công cụ (tools/API), ta có thể:\nChia nhỏ nhiệm vụ thành nhiều bước rõ ràng Gọi API để truy xuất và xử lý dữ liệu Ghép kết quả thành câu trả lời cuối cùng có giải thích 2. Tool trong bối cảnh LLM Tool là khả năng bên ngoài mà LLM có thể gọi:\nAPI truy xuất dữ liệu Hàm chạy Python/SQL Lọc, nhóm, join dữ liệu Duyệt web hoặc xử lý file Nhờ tool, LLM không chỉ trả lời bằng văn bản mà thực sự thực thi logic, giúp kết quả chính xác hơn.\n3. Ví dụ tương tác với agent User: “Ai là bệnh nhân có số vaccine ít nhất?”\nAI: “Bệnh nhân Sharleen176 Kulas532 có 1 vaccine.”\nCác bước agent thực hiện:\nLấy danh sách bệnh nhân Lấy hồ sơ tiêm chủng Nhóm theo bệnh nhân Đếm số vaccine Sắp xếp tăng dần Lấy bản ghi đầu tiên Join để lấy tên đầy đủ Trả về kết quả 4. Dataset \u0026amp; thiết lập Giải pháp dùng Synthetic Patient Generation Dataset, một dataset y tế mô phỏng.\nTải và giải nén:\nTải file dataset Giải nén Chuyển thư mục về dataset/ 5. Kiến trúc Plan → Execute Kiến trúc gồm 2 giai đoạn:\nPlan: LLM lập kế hoạch từng bước Execute: Engine chạy từng bước Luồng xử lý:\nUser → LLM tạo kế hoạch → JSON Plan → Engine Execute → Kết quả cuối\n6. Giai đoạn Plan 6.1. Lý do cần Plan LLM suy luận tuần tự Tạo chuỗi hành động có cấu trúc Giảm lỗi bịa API Tách Plan \u0026amp; Execute giúp dễ debug và mở rộng.\n6.2. Tool signatures LLM được cung cấp danh sách hàm hợp lệ (toolbox):\nLấy bệnh nhân Lấy hồ sơ tiêm chủng Lọc dữ liệu Join dữ liệu Nhóm và sắp xếp dữ liệu LLM không được tự tạo hàm mới.\n6.3. Dùng RAG để lọc tool phù hợp RAG giúp:\nHiển thị đúng tool liên quan Giảm độ phức tạp của prompt Tránh LLM chọn sai hàm 6.4. Kế hoạch ví dụ Truy vấn: “Tìm bệnh nhân có số vaccine ít nhất.”\nKế hoạch gồm:\nLấy bệnh nhân Lấy tiêm chủng Nhóm theo bệnh nhân và đếm Sắp xếp tăng dần Lấy bản ghi đầu Join Select các trường cần thiết 7. Giai đoạn Execute Engine sẽ:\nParse JSON Thực thi từng bước Lưu kết quả trung gian Trả kết quả cuối Pipeline:\nLấy tiêm chủng → Nhóm → Sắp xếp → Giới hạn → Join → Select\nLLM sau đó diễn giải kết quả thành câu trả lời tự nhiên.\n8. Xử lý lỗi Lỗi có thể gồm:\nDataset rỗng Tham số sai Kiểu dữ liệu không khớp khi join/filter Engine cần:\nKiểm tra tham số Kiểm tra input/output Trả thông tin lỗi LLM có thể tự tạo lại kế hoạch.\n9. Kết luận Chúng ta đã hiểu cách:\nLLM dùng API để trả lời truy vấn phức tạp Kiến trúc Plan → Execute hoạt động RAG và function signatures giúp LLM lập kế hoạch chính xác Error handling giúp hệ thống ổn định LLM giờ đây có thể trở thành bộ não điều phối quy trình phân tích dữ liệu, không chỉ sinh văn bản.\n10. Hướng phát triển Có thể mở rộng:\nThêm truy vấn phân tích nâng cao Thêm tool signatures mới Xây dựng UI để nhập câu hỏi và xem plan/log Giải pháp vừa mang tính học thuật vừa gần thực tế doanh nghiệp.\n"
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lê Minh Dương\nSố điện thoại: 0347622638\nEmail: leduong5469@gmail.com\nTrường: Đại học FPT Ngành: An Toàn Thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 1: Kết nối và làm quen với các thành viên của First Cloud Journey. Hiểu các dịch vụ cơ bản của AWS, cách sử dụng AWS Management Console và AWS CLI. Tạo một tài khoản AWS. Xem video hướng dẫn cài đặt Hugo, Git, VSCode. Học cách viết Markdown, học cách sử dụng Hugo. Thực hành các lab trong First Cloud Journey. Các công việc cần thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 Làm quen với các thành viên FCJĐọc và ghi chú lại quy định của đơn vị thực tập 08/09/2025 08/09/2025 3 Tìm hiểu về AWS và các loại dịch vụ:ComputeStorageNetworkingDatabase 09/09/2025 09/09/2025 CloudJourney 4 Tạo tài khoản AWS Free TierHọc về AWS Console \u0026amp; AWS CLIThực hành:Tạo tài khoản AWSCài đặt \u0026amp; cấu hình AWS CLICách sử dụng AWS CLI 10/09/2025 10/09/2025 AWS Account Setup 5 Học cách viết Markdown và sử dụng Hugo 11/09/2025 11/09/2025 YouTube Guide 6 Thực hành:Làm các lab trong First Cloud Journey 12/09/2025 12/09/2025 First Cloud Journey Thành tựu Tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database Đã tạo và cấu hình thành công một tài khoản AWS Free Tier.\nLàm quen với AWS Management Console, biết cách tìm kiếm, truy cập và sử dụng dịch vụ thông qua giao diện web.\nĐã cài đặt và cấu hình thành công AWS CLI trên máy tính, bao gồm:\nAccess Key Secret Key Default Region Cài đặt thành công Hugo, Git và VSCode:\nBiết cách sử dụng Hugo, Git và VSCode.\nBiết cách viết Markdown và đã viết thành công Worklog Tuần 1.\n"
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/5-workshop/5.2-pipline-flow/",
	"title": "Pipline-flow",
	"tags": [],
	"description": "",
	"content": "CodePipeline Flow (GitLab → AWS) 1. Source Stage CodePipeline được cấu hình lắng nghe commit từ GitLab (branch: main). Khi có commit mới, pipeline tự động kích hoạt. Output: source artifact để truyền sang bước build. 2. Build Stage (CodeBuild) Chạy môi trường build theo buildspec.yml. Thực thi: Cài Sonar Scanner. Quét toàn bộ source code. Gửi kết quả sang SonarQube Server. Nếu build fail → pipeline dừng. 3. Post-Build Actions CodeBuild đẩy metadata build (log, status) về CodePipeline. Notify optional: Amazon EventBridge / SNS / Slack. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Báo Cáo Workshop: \u0026ldquo;DevOps on AWS\u0026rdquo; Mục Tiêu Sự Kiện Hiểu rõ văn hóa DevOps, giá trị cốt lõi và các thực hành tốt nhất Làm quen với các dịch vụ AWS hỗ trợ xây dựng CI/CD Thực hành Infrastructure as Code bằng CloudFormation và AWS CDK Tìm hiểu các nền tảng container trên AWS: ECR, ECS, EKS và App Runner Nắm cách giám sát – quan sát hệ thống bằng CloudWatch và AWS X-Ray Áp dụng DevOps vào các bài toán thực tế trong doanh nghiệp Thông Tin Sự Kiện Địa điểm: Văn phòng AWS Vietnam Thời gian: 8:30 AM – 5:00 PM, Thứ Hai, 17/11/2025 Diễn Giả \u0026amp; Ban Tổ Chức Diễn giả chính:\nTrương Quang Tĩnh – AWS Community Builder Giới thiệu văn hoá DevOps và nền tảng CI/CD Văn Hoàng Kha – AWS Community Builder Trình bày Infrastructure as Code với CloudFormation Nguyễn Khánh Phúc Thịnh – AWS Community Builder Hướng dẫn chuyên sâu AWS CDK Lê Huỳnh Nghiêm – AWS Community Builder Giới thiệu dịch vụ container trên AWS Huỳnh Hoàng Long – AWS Community Builder Giám sát và quan sát hệ thống với AWS Phạm Hoàng Quý – AWS Community Builder Văn hoá DevOps và chia sẻ case study thực tế Hỗ trợ tổ chức:\nĐội ngũ AWS Vietnam Cộng đồng AWS Community Builders Vietnam Agenda Chi Tiết 8:30 – 9:00 AM: Đón Tiếp \u0026amp; Khởi Động Check-in, giao lưu Giới thiệu nội dung buổi workshop Tổng quan các dịch vụ DevOps trên AWS 9:00 – 10:30 AM: Văn Hóa DevOps \u0026amp; Quy Trình CI/CD Diễn giả: Trương Quang Tĩnh\nTư duy DevOps:\nXoá bỏ rào cản giữa Dev và Ops Tự động hóa để giảm công việc lặp lại Cải tiến liên tục Trách nhiệm chung về chất lượng và an toàn DORA Metrics – các chỉ số đo hiệu quả DevOps:\nDeployment Frequency Lead Time for Changes Mean Time to Recovery Change Failure Rate Các dịch vụ CI/CD trên AWS:\nCodeCommit – kho Git trên AWS CodeBuild – build/test tự động CodeDeploy – triển khai ứng dụng CodePipeline – pipeline CI/CD tổng thể Chiến lược triển khai:\nBlue/Green Canary Rolling update Demo:\nXây dựng pipeline CI/CD hoàn chỉnh ngay trong buổi học 10:30 – 10:45 AM: Nghỉ Giải Lao 10:45 AM – 12:00 PM: Infrastructure as Code với CloudFormation Diễn giả: Văn Hoàng Kha\nNguyên lý của IaC:\nQuản lý bằng version control Môi trường triển khai luôn đồng nhất Documentation nằm ngay trong template Test trước khi áp dụng CloudFormation cơ bản:\nTemplate (YAML/JSON) Stack Change Set Drift Detection Thực hành tốt:\nTách template theo mô-đun Dùng Parameter và Output Cross-stack reference Tính năng nâng cao:\nStack Policy Rollback Trigger StackSets Demo:\nTriển khai ứng dụng 2–3 tầng bằng CloudFormation 12:00 – 1:00 PM: Nghỉ Trưa 1:00 – 2:15 PM: Chuyên Sâu AWS CDK Diễn giả: Nguyễn Khánh Phúc Thịnh\nAWS CDK là gì?\nViết hạ tầng bằng các ngôn ngữ quen thuộc (TS, Python, Java, C#, Go) Abstraction theo 3 tầng: L1, L2, L3 Khái niệm cốt lõi trong CDK:\nConstruct Stack App Synthesis CDK so với CloudFormation:\nCó vòng lặp, điều kiện, function An toàn kiểu dữ liệu Hỗ trợ IDE tốt hơn Test được bằng unit test Thực hành tốt CDK:\nTái sử dụng construct Tách cấu hình theo môi trường Giữ Logical ID ổn định Demo:\nBuild serverless app bằng CDK 2:15 – 2:30 PM: Nghỉ Ngắn 2:30 – 3:45 PM: Container trên AWS Diễn giả: Lê Huỳnh Nghiêm\nKiến thức container nền tảng:\nContainer là gì, ưu điểm của container Docker image, container, registry ECR:\nPrivate registry Image scanning Lifecycle policy Multi-region replication ECS:\nOrchestration gọn nhẹ, thuần AWS Task Definition Service Fargate vs EC2 launch type EKS:\nManaged Kubernetes Dùng kubectl, helm bình thường Tích hợp tốt với ALB, EBS, EFS App Runner:\nTừ source code → service chỉ với vài bước Tự động scale Dùng cho app nhỏ, API, web service Chọn dịch vụ nào?\nECS → đơn giản, AWS-native EKS → cần Kubernetes chuyên sâu App Runner → siêu nhanh, ít cấu hình Demo:\nDeploy app container lên ECS và EKS 3:45 – 4:45 PM: Monitoring \u0026amp; Observability Diễn giả: Huỳnh Hoàng Long\nMonitoring vs Observability:\nMonitoring → thu thập thông số Observability → hiểu hệ thống qua hành vi đầu ra CloudWatch:\nMetrics Logs Alarms Dashboard Logs Insights Events AWS X-Ray:\nDistributed tracing Service Map Trace analysis Error root cause detection Best Practice:\nStructured log Custom metric Alert chủ động Correlate log – metric – trace Quản lý retention hợp lý Demo:\nThiết lập giám sát cho ứng dụng microservices 4:45 – 5:00 PM: DevOps Best Practices \u0026amp; Q\u0026amp;A Diễn giả: Phạm Hoàng Quý\nBest Practice trong DevOps:\nTự động hóa tối đa Fail fast – học nhanh Postmortem không đổ lỗi Progressive delivery Học hỏi liên tục Case Study thực tế:\nStartup → CI/CD + serverless Enterprise → Multi-account bằng StackSets E-commerce → Blue/Green cho high-availability Những Điểm Chính Rút Ra Văn Hóa DevOps DevOps chú trọng con người và quy trình hơn công cụ Automation giúp giảm sai sót DORA Metrics là nền tảng để đo hiệu quả Cải tiến liên tục là yếu tố bắt buộc CI/CD CodePipeline kết hợp tốt với CodeCommit, CodeBuild, CodeDeploy Giảm manual work, tăng tốc độ release Triển khai đa chiến lược phù hợp từng môi trường Infrastructure as Code CloudFormation → rõ ràng, quản lý tập trung CDK → linh hoạt, thân thiện dev IaC giúp nhất quán và dễ mở rộng Container ECR lưu trữ image an toàn ECS phù hợp team dùng AWS EKS dành cho team rành Kubernetes App Runner dành cho app nhỏ, cần triển khai nhanh Monitoring CloudWatch + X-Ray tạo hệ thống quan sát đầy đủ Logs, metrics, traces cần được kết hợp Cảnh báo sớm giúp giảm downtime DevOps Best Practices Tự động hóa, đo lường, cải tiến Postmortem tập trung vào quy trình Progressive delivery giảm rủi ro Ứng Dụng Vào Công Việc Bắt đầu xây pipeline CI/CD nhỏ với CodePipeline Chuyển hạ tầng sang IaC bằng CloudFormation/CDK Containerize ứng dụng và thử ECS/EKS Thiết lập dashboard CloudWatch + tracing Thúc đẩy văn hóa DevOps trong team Lên kế hoạch học chứng chỉ AWS DevOps Engineer Trải Nghiệm Tại Sự Kiện Buổi workshop rất chi tiết và dễ hiểu Demo thực tế giúp nắm bắt nhanh hơn phần lý thuyết Tìm hiểu được nhiều case study thực tế từ doanh nghiệp Việt Nam Cơ hội giao lưu với cộng đồng DevOps trên AWS Bước Tiếp Theo Thực hành CI/CD trên dự án nhỏ Dùng CloudFormation/CDK cho các môi trường dev/test Dùng ECS hoặc EKS cho các ứng dụng container sẵn có Cải thiện hệ thống quan sát bằng dashboard và alert Tiếp tục học từ cộng đồng AWS DevOps "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/3-blogstranslated/3.2-blog2/",
	"title": "Cập nhật phương pháp Carbon cho Công cụ Dấu Chân Carbon của Khách Hàng AWS (CCFT)",
	"tags": [],
	"description": "",
	"content": "(Theo tài liệu gốc AWS, cập nhật ngày 23/04/2025)\nĐể hỗ trợ hành trình bền vững của khách hàng, AWS đã ra mắt Công cụ Dấu chân Carbon của Khách hàng (Customer Carbon Footprint Tool – CCFT) vào năm 2022. CCFT giúp khách hàng theo dõi, đo lường và xem xét lượng khí thải carbon phát sinh từ việc sử dụng AWS, bao gồm khí thải Scope 1 và Scope 2 theo chuẩn Greenhouse Gas Protocol. Các số liệu được tính cho toàn bộ dải dịch vụ AWS như Amazon EC2, Amazon S3, AWS Lambda và nhiều dịch vụ khác.\nHôm nay, AWS công bố ba cập nhật mới cho CCFT:\nDễ dàng truy cập dữ liệu hơn thông qua dịch vụ Billing and Cost Management Data Exports. Thông tin carbon chi tiết hơn theo từng vùng AWS (Regional Granularity). Phương pháp phân bổ mới (Methodology v2.0), có xác minh độc lập từ APEX. Từ tháng 1 năm 2025 trở về sau, CCFT sẽ sử dụng phương pháp v2.0. Dữ liệu trước tháng 12/2024 vẫn dùng phương pháp v1.0.\n1. Làm cho việc truy cập dữ liệu dễ hơn Khách hàng hiện có thể xuất dữ liệu carbon từ CCFT thông qua AWS Data Exports trong Billing and Cost Management.\nDữ liệu xuất ra:\nBao gồm ước tính khí thải carbon cho tất cả tài khoản trong AWS Organizations. Được gửi tự động mỗi tháng dưới dạng CSV hoặc Parquet vào Amazon S3. Bao gồm tối đa 38 tháng dữ liệu lịch sử trong lần xuất đầu tiên. Các tháng trước 12/2024 dùng v1.0, từ 1/2025 trở đi dùng v2.0.\n2. Chi tiết theo vùng AWS (Regional Granularity) Khách hàng giờ có thể xem lượng khí thải carbon chia nhỏ theo từng AWS Region.\nRiêng Amazon CloudFront được hiển thị dưới một mục Global Services.\nĐiều này giúp khách hàng:\nXác định vùng nào tiêu tốn nhiều carbon nhất. Cân nhắc tái phân bổ workloads sang các vùng tối ưu hơn. 3. Phương pháp phân bổ (Methodology) v2.0 Khách hàng thường sử dụng nhiều dịch vụ trải dài nhiều vùng AWS, khiến việc phân bổ khí thải trở nên phức tạp.\nPhương pháp mới v2.0 tuân theo nhiều tiêu chuẩn quốc tế gồm:\nGHG Protocol Corporate Standard GHG Protocol Product Standard ISO 14040/44 (Life Cycle Assessment) ISO 14067 (Carbon footprint of products) ICT Sector Guidance Một số điểm chính:\nPhân bổ Scope 1 (Trực tiếp) Scope 1 bao gồm khí thải trực tiếp từ các nguồn AWS sở hữu hoặc kiểm soát, ví dụ:\nMáy phát dự phòng tại data centers Nhiên liệu sử dụng phục vụ vận hành AWS thu thập dữ liệu Scope 1 hàng năm, cấp site, rồi tổng hợp lên cấp cluster (vùng AWS hoặc CloudFront edge cluster).\nPhân bổ Scope 2 (Gián tiếp) Scope 2 bao gồm khí thải gián tiếp từ điện mua từ lưới.\nCCFT sử dụng phương pháp:\nMarket-based Hệ số phát thải dựa trên vị trí địa lý Theo thứ tự ưu tiên của GHG Protocol Nguồn dữ liệu về năng lượng tái tạo, grid mix và hệ số phát thải được xác minh hàng năm.\nTổng quan phân bổ v2.0 Quy trình phân bổ gồm 3 bước:\nPhân bổ khí thải cấp cluster cho từng giá đỡ máy chủ (server rack). Ánh xạ khí thải từ các giá đỡ đến từng dịch vụ AWS dựa vào mức sử dụng tài nguyên. Phân bổ khí thải từ dịch vụ AWS đến từng tài khoản khách hàng. Một số khách hàng có thể thấy số liệu thay đổi vì v2.0 phản ánh chính xác hơn việc sử dụng thực tế.\nBa cập nhật chính trong phương pháp v2.0 Phân bổ phần công suất chưa dùng (unused capacity) cho tất cả khách hàng.\nAWS luôn phải xây dựng dư công suất, và phần carbon liên quan đến công suất này giờ sẽ được phân bổ đều theo quy định của GHG Protocol \u0026amp; ISO.\nCải thiện logic phân bổ cho dịch vụ không có phần cứng riêng (như AWS Lambda, Amazon Redshift).\nPhân bổ rõ ràng giữa khách hàng AWS và đội ngũ nội bộ Amazon.\nCập nhật phân bổ chi phí chung (overhead) như:\nGiá đỡ mạng Chi phí mở rộng AWS Regions mới Tương lai AWS sẽ tiếp tục cải thiện CCFT dựa trên dữ liệu mới, khoa học khí hậu và nhu cầu khách hàng.\nCam kết The Climate Pledge AWS tiếp tục cam kết hướng tới net-zero carbon vào năm 2040.\nĐể tìm hiểu thêm, khách hàng có thể truy cập trang bền vững của AWS.\n"
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/2-proposal/",
	"title": "Đề Xuất",
	"tags": [],
	"description": "",
	"content": "Dự Án AWS Security Scan – Kế Hoạch Dự Án [Team DevSecOps FCJ] – [Đại học FPT / Chương trình Thực tập] – [Dự Án AWS Security Scan] Date: 2025-10-11\nMỤC LỤC NỀN TẢNG VÀ ĐỘNG LỰC 1.1 TÓM TẮT ĐIỀU HÀNH\n1.2 TIÊU CHÍ THÀNH CÔNG CỦA DỰ ÁN\n1.3 CÁC GIẢ ĐỊNH\nKIẾN TRÚC GIẢI PHÁP / SƠ ĐỒ KIẾN TRÚC 2.1 SƠ ĐỒ KIẾN TRÚC KỸ THUẬT\n2.2 KẾ HOẠCH KỸ THUẬT\n2.3 KẾ HOẠCH DỰ ÁN\n2.4 CÁC LƯU Ý BẢO MẬT\nHOẠT ĐỘNG VÀ SẢN PHẨM BÀN GIAO 3.1 HOẠT ĐỘNG VÀ SẢN PHẨM BÀN GIAO\n3.2 PHẠM VI LOẠI TRỪ\n3.3 LỘ TRÌNH LÊN PRODUCTION\nDỰ TRÙ CHI PHÍ AWS THEO DỊCH VỤ\nĐỘI NGŨ\nTÀI NGUYÊN \u0026amp; CHI PHÍ ƯỚC TÍNH\nNGHIỆM THU\n1. NỀN TẢNG VÀ ĐỘNG LỰC 1.1 TÓM TẮT ĐIỀU HÀNH Dự án AWS Security Scan nhằm tự động hóa quy trình kiểm tra bảo mật trên toàn bộ vòng đời phát triển phần mềm bằng cách tích hợp các dịch vụ AWS như CodePipeline, CodeBuild, CodeGuru Reviewer và AWS Security Hub.\nSáng kiến này giúp tăng cường khả năng bảo mật của pipeline CI/CD bằng cách tích hợp quét lỗ hổng tự động, phân tích mã nguồn bằng AI và giám sát sự cố tập trung.\nCác trường hợp sử dụng bao gồm:\nTích hợp liên tục với xác thực bảo mật tích hợp sẵn Cảnh báo tự động và báo cáo tuân thủ Quan sát thời gian thực về lỗ hổng và chất lượng mã Dịch vụ của đối tác tập trung vào thiết kế, triển khai và tối ưu hóa pipeline DevSecOps, đảm bảo phân phối phần mềm an toàn, tuân thủ và hiệu quả.\n1.2 TIÊU CHÍ THÀNH CÔNG CỦA DỰ ÁN ≥95% các commit vượt qua quét bảo mật tự động trước khi triển khai Cảnh báo thời gian thực trong vòng 2 phút khi phát hiện bất thường Điểm tuân thủ Security Hub ≥90% Tích hợp thành công giữa CodePipeline, CodeBuild và Security Hub mà không cần thao tác thủ công 1.3 CÁC GIẢ ĐỊNH Tất cả tài khoản AWS đã được cấu hình IAM phù hợp cho CodePipeline và CodeBuild GitLab bật webhook và cấp quyền đầy đủ Các công cụ bảo mật (Trivy, Bandit, SonarQube) sẵn sàng trong môi trường CodeBuild Tổ chức tuân thủ AWS Well-Architected Framework và các best practice bảo mật 2. KIẾN TRÚC GIẢI PHÁP / SƠ ĐỒ KIẾN TRÚC 2.1 SƠ ĐỒ KIẾN TRÚC KỸ THUẬT Giải pháp đề xuất tích hợp nhiều dịch vụ AWS cho CI/CD, phân tích bảo mật tự động và giám sát.\nBao gồm các thành phần: GitLab (source), CodeBuild (build/test), CodePipeline (orchestrator), CodeGuru Reviewer (AI code review), Security Hub + SNS (cảnh báo tập trung).\nCông cụ sử dụng: GitLab AWS CodePipeline AWS CodeBuild AWS CodeGuru Reviewer AWS Security Hub, GuardDuty, Detective SonarQube, Trivy, Bandit 2.2 KẾ HOẠCH KỸ THUẬT Đối tác sẽ xây dựng các file buildspec YAML cho CodeBuild để tự động:\nQuét mã nguồn (Trivy, Bandit) Phân tích mã tĩnh (CodeGuru Reviewer) Đóng gói và kích hoạt triển khai Tất cả triển khai được quản lý version qua GitLab CI triggers.\nCác file cấu hình tuân theo nguyên tắc Infrastructure as Code bằng AWS CloudFormation.\n2.3 KẾ HOẠCH DỰ ÁN Nhóm áp dụng Agile Scrum trong 4 sprint (mỗi sprint 2 tuần).\nStakeholder tham gia Sprint Review và Retrospective.\nVai trò:\nDevOps Engineer: Thiết lập pipeline CI/CD Security Engineer: Tích hợp và phân tích bảo mật Project Lead: Điều phối, báo cáo, tài liệu Họp sync hàng tuần qua Slack và AWS Chime.\n2.4 CÁC LƯU Ý BẢO MẬT Truy cập: IAM least privilege, MFA cho tài khoản admin Hạ tầng: Subnet riêng tư cho build agents Dữ liệu: Mã hóa S3 (SSE-KMS), mã hóa log CodeBuild Giám sát: GuardDuty và Security Hub theo dõi liên tục Quản lý sự cố: SNS + CloudWatch Alarms 3. HOẠT ĐỘNG VÀ SẢN PHẨM BÀN GIAO 3.1 HOẠT ĐỘNG VÀ SẢN PHẨM BÀN GIAO Giai đoạn dự án Thời gian Hoạt động Sản phẩm / Mốc hoàn thành Man-days Đánh giá Tuần 1–2 Phân tích CI/CD hiện tại Báo cáo \u0026amp; thiết kế kiến trúc 5 Thiết lập hạ tầng cơ bản Tuần 3–4 Tạo CodePipeline \u0026amp; CodeBuild Pipeline triển khai hoàn chỉnh 7 Tích hợp công cụ bảo mật Tuần 5–6 Thêm SonarQube, Trivy, Bandit Bật tính năng quét bảo mật 6 Thiết lập giám sát Tuần 7 Kết nối Security Hub, CloudWatch Hệ thống cảnh báo hoạt động 4 Kiểm thử \u0026amp; Go-Live Tuần 8 Kiểm thử cuối, tài liệu Báo cáo Go-Live 3 Bàn giao Tuần 9 Chuyển giao \u0026amp; hướng dẫn Tài liệu bàn giao cuối 2 3.2 PHẠM VI LOẠI TRỪ Quét bảo mật ứng dụng on-premises Các framework tuân thủ không thuộc AWS CI/CD ngoài AWS 3.3 LỘ TRÌNH LÊN PRODUCTION PoC tập trung vào tích hợp DevSecOps native trên AWS.\nĐể đưa vào production, cần thêm các bước như multi-account, cô lập mạng, tự động vá lỗi.\n4. DỰ TRÙ CHI PHÍ AWS THEO DỊCH VỤ Dịch vụ Mô tả Ước tính chi phí/tháng (USD) CodePipeline Orchestration 10 CodeBuild Build + Quét 30 CodeGuru Reviewer Phân tích mã 25 Security Hub Tổng hợp + Cảnh báo 15 CloudWatch Logs + Metrics 10 S3 Lưu artifact 5 SNS Thông báo 5 Tổng 100 USD/tháng 5. ĐỘI NGŨ Tên MSSV Email / Liên hệ Lê Công Cảnh SE183750 canhlcse183750@fpt.edu.vn Phùng Gia Đức SE183187 ducpgse183187@fpt.edu.vn Vũ Nguyễn Bình SE193185 vunguyenbinh25@gmail.com Lê Minh Dương SE184079 duonglmse184079@fpt.edu.vn Nguyễn Phi Duy SE180529 duynpse180529@fpt.edu.vn 6. TÀI NGUYÊN \u0026amp; CHI PHÍ ƯỚC TÍNH Vai trò Trách nhiệm Rate (USD/hr) Số giờ Chi phí (USD) Solution Architect Thiết kế \u0026amp; rà soát 60 40 2400 DevOps Engineer Triển khai pipeline 45 60 2700 Security Engineer Tích hợp công cụ bảo mật 50 50 2500 Tổng 150 7600 7. NGHIỆM THU Sau mỗi giai đoạn, đối tác sẽ gửi sản phẩm bàn giao để khách hàng đánh giá.\nKhách hàng có 8 ngày làm việc để:\nGửi chấp nhận bằng văn bản, hoặc Gửi phản hồi từ chối cùng góp ý Nếu không phản hồi trong thời hạn, sản phẩm được xem như được nghiệm thu.\n"
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 2 Objectives: Nắm toàn bộ nội dung Module 01. Hiểu hạ tầng AWS và các công cụ quản lý dịch vụ. Thực hành tối ưu chi phí với AWS Budgets. Hoàn thành lab tài khoản IAM và Billing. Làm quen AWS Support. Tasks to be carried out this week: Day Task Start End Reference 2 Module 01-04: Global InfrastructureModule 01-05: Service Management 15/09 15/09 FCJ Module 01 3 Module 01-06: Cost OptimizationLab 07-01 → 07-03 16/09 16/09 FCJ Lab 07 4 Lab 07-04 → 07-06Tạo Cost/Usage/Savings Budget 17/09 17/09 AWS Billing 5 Lab 01-01 → 01-04 (IAM) 18/09 18/09 FCJ Lab 01 6 Tìm hiểu AWS Support PlansTạo support case mẫu 19/09 19/09 AWS Support Docs Week 2 Achievements: Hiểu rõ hạ tầng AWS (Region, AZ…) Quản lý chi phí tốt hơn thông qua AWS Budgets. Thành thạo lab IAM cơ bản. Nắm quy trình AWS Support. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/5-workshop/5.3-sonarqube-analysis/",
	"title": "Sonarqube-analysis",
	"tags": [],
	"description": "",
	"content": "SonarQube Analysis Architecture Sonar Scanner → SonarQube Trong giai đoạn build, Sonar Scanner thực hiện:\nPhân tích chất lượng code. Phát hiện bug. Phát hiện lỗ hổng bảo mật (Security Hotspots, Vulnerabilities). Tính toán code smell, độ phức tạp, duplication. Kết quả được gửi tới:\nSonarQube Server (EC2) SonarQube xử lý, lưu kết quả vào database của nó. Webhook Trigger Khi quá trình phân tích hoàn tất:\nSonarQube gọi HTTP POST tới API Gateway endpoint. Payload chứa: Tên project Trạng thái Quality Gate (Pass/Fail) Summary lỗi (bugs, vulnerabilities, code smells,…) "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Báo Cáo Workshop: \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; Thông Tin Sự Kiện Ngày: 29/11/2025 — Buổi sáng Thời gian: 08:30 AM – 12:00 PM Địa điểm: AWS Vietnam Office Danh Sách Diễn Giả Lê Vũ Xuân An – AWS Cloud Club Captain HCMUTE Trần Đức Anh – AWS Cloud Club Captain SGU Trần Đoàn Công Lý – AWS Cloud Captain PTIT Danh Hoàng Hiếu Nghị – AWS Cloud Captain HUFLIT 8:30 – 8:50 AM | Opening \u0026amp; Security Foundation Vai trò của Security Pillar trong mô hình Well-Architected Các nguyên tắc quan trọng: Least Privilege, Zero Trust, Defense in Depth Shared Responsibility Model Các mối đe dọa phổ biến trong môi trường cloud tại Việt Nam Pillar 1 — Identity \u0026amp; Access Management 8:50 – 9:30 AM | Modern IAM Architecture IAM: Users, Roles, Policies – hạn chế dùng long-term credentials IAM Identity Center: SSO, permission sets SCP và permission boundaries cho multi-account MFA, credential rotation, Access Analyzer Mini Demo: Validate IAM Policy + simulate access Pillar 2 — Detection 9:30 – 9:55 AM | Detection \u0026amp; Continuous Monitoring CloudTrail (cấp tổ chức), GuardDuty, Security Hub Logging toàn hệ thống: VPC Flow Logs, ALB Logs, S3 Access Logs Alerting và automation với EventBridge Detection-as-Code (quản lý rule + hạ tầng bằng code) 9:55 – 10:10 AM | Coffee Break Pillar 3 — Infrastructure Protection 10:10 – 10:40 AM | Network \u0026amp; Workload Security VPC segmentation: private vs public placement Security Groups vs NACLs – mô hình áp dụng WAF, Shield, Network Firewall Bảo vệ workload: EC2, ECS/EKS, security basics Pillar 4 — Data Protection 10:40 – 11:10 AM | Encryption, Keys \u0026amp; Secrets KMS: key policies, grants, rotation Encryption at-rest \u0026amp; in-transit: S3, EBS, RDS, DynamoDB Secrets Manager \u0026amp; Parameter Store – best practices \u0026amp; rotation Data classification \u0026amp; access guardrails Pillar 5 — Incident Response 11:10 – 11:40 AM | IR Playbook \u0026amp; Automation Vòng đời Incident Response theo AWS Playbooks mẫu: Compromised IAM key S3 public exposure EC2 malware detection Snapshot, isolation, evidence collection Auto-response bằng Lambda / Step Functions 11:40 AM – 12:00 PM | Wrap-Up \u0026amp; Q\u0026amp;A Tổng kết 5 pillars Sai sót thường gặp \u0026amp; ví dụ thực tế tại doanh nghiệp Việt Nam Roadmap security learning (Security Specialty, SA Pro) "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/3-blogstranslated/3.3-blog3/",
	"title": "Sử dụng thông tin tham chiếu dịch vụ AWS để tự động hóa luồng công việc quản lý chính sách",
	"tags": [],
	"description": "",
	"content": "AWS cung cấp một bộ tài liệu tham chiếu dịch vụ (AWS service reference information) nhằm hỗ trợ doanh nghiệp quản lý việc sử dụng dịch vụ AWS một cách bảo mật và hiệu quả. Bộ tham chiếu này bao gồm thông tin chi tiết về quyền IAM, dữ liệu, API, hành động, và điều kiện của từng dịch vụ. Khách hàng có thể sử dụng tập dữ liệu này để tự động hóa quy trình tạo, đánh giá và quản lý chính sách IAM.\nDưới đây là cách AWS mô tả cách sử dụng tập thông tin này để tự động hóa việc quản lý chính sách.\n1. Tổng quan về mục đích của bộ tham chiếu dịch vụ AWS Bộ tham chiếu dịch vụ AWS giúp bạn:\nTự động hóa tạo IAM policy. Phân tích việc sử dụng dịch vụ để phát hiện quyền dư thừa. Giảm thiểu quyền cấp dư và tối ưu bảo mật theo nguyên tắc least privilege. Tích hợp vào hệ thống review, kiểm toán, hoặc thay đổi policy. Bộ tham chiếu bao gồm các thông tin sau:\nToàn bộ hành động mà mỗi dịch vụ AWS hỗ trợ. Quyền IAM tương ứng với từng hành động. Các tài nguyên (resources) mà hành động đó có thể tác động. Điều kiện (condition keys) mà hành động hỗ trợ. 2. Các mô hình sử dụng chính Doanh nghiệp có thể áp dụng thông tin tham chiếu dịch vụ AWS trong nhiều trường hợp:\nTự động tạo IAM policy theo thực tế sử dụng Bằng cách kết hợp dữ liệu CloudTrail với bộ tham chiếu dịch vụ, hệ thống có thể:\nPhân tích hành động mà ứng dụng thực sự sử dụng. Gợi ý IAM policy theo thực tế (just-in-time policy generation). Tránh cấp quyền vượt mức. Tối ưu policy hiện có Công cụ tự động có thể:\nXác định hành động không còn sử dụng. Gợi ý loại bỏ quyền dư thừa. Phát hiện sự khác biệt giữa quyền được cấp và quyền được dùng. Hỗ trợ viết policy chuẩn xác Bộ tham chiếu cung cấp:\nTên hành động IAM đúng chuẩn. Danh sách “resource types” mà action hỗ trợ. Các condition keys phù hợp. Điều này giảm lỗi sai khi viết policy thủ công.\nTự động hóa quy trình đánh giá và phê duyệt policy Bạn có thể dùng bộ tham chiếu để:\nKiểm tra policy trước khi phê duyệt. Xác nhận hành động IAM có hợp lệ hay không. Tự động reject các policy yêu cầu quyền không cần thiết. 3. Dữ liệu có sẵn trong bộ tham chiếu Bộ dữ liệu tham chiếu dịch vụ AWS bao gồm:\nDanh sách dịch vụ AWS. Tập hợp các action của IAM cho từng dịch vụ. Resource type mà mỗi action hỗ trợ. Condition keys được phép sử dụng. Tài liệu định nghĩa quyền và API tương ứng. Nguồn dữ liệu được cập nhật hàng tháng.\n4. Tự động hóa luồng công việc quản lý policy Doanh nghiệp có thể xây dựng hệ thống kết hợp:\nCloudTrail (ghi lại sử dụng API thực tế). AWS IAM policy reference dataset (để xác định action/resource phù hợp). Quy trình CI/CD hoặc phê duyệt policy. Luồng hoạt động điển hình:\nThu thập dữ liệu sử dụng API từ CloudTrail. So sánh với bộ tham chiếu IAM để xác định quyền thực sự cần. Tạo hoặc gợi ý policy mới. Tự động gửi đến pipeline phê duyệt. Tự động cập nhật policy trong IAM. 5. Lợi ích chính Tăng độ bảo mật nhờ giới hạn quyền ở mức tối thiểu. Tự động hóa quy trình vốn tốn thời gian khi làm thủ công. Giảm lỗi do con người. Dễ dàng theo dõi sự thay đổi quyền theo thời gian. Tích hợp tốt với các hệ thống DevOps. 6. Kết luận Bộ tham chiếu dịch vụ AWS cung cấp nền tảng quan trọng giúp doanh nghiệp tự động hóa việc quản lý IAM policy, đảm bảo tuân thủ bảo mật và tối ưu hóa quyền truy cập. Khi kết hợp với CloudTrail và workflow automation, doanh nghiệp có thể xây dựng hệ thống quản lý policy thông minh, chính xác và ít rủi ro.\n"
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 3 Objectives: Hiểu kiến trúc mạng AWS: VPC, Subnet, Route Table. Thực hành Module 02 phần VPC cơ bản. Làm quen các thành phần Network Security: SG \u0026amp; NACL. Tasks this week: Day Task Start End Reference 2 Xem Module 02-01 → 02-02Chuẩn bị lý thuyết VPC 22/09 22/09 FCJ Module 02 3 Tạo VPC + SubnetsCấu hình Route Table 23/09 23/09 Lab 03 4 Tạo Internet GatewayTạo NAT Gateway 24/09 24/09 VPC Labs 5 Cấu hình Security GroupsSo sánh SG vs NACL 25/09 25/09 Module 02 6 Test ping/SSH giữa các subnet 26/09 26/09 Lab Test Week 3 Achievements: Hiểu mô hình mạng AWS hoạt động như thế nào. Tạo được VPC đầy đủ thành phần và routing. Phân biệt SG \u0026amp; NACL và biết khi nào dùng loại nào. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Sử dụng Large Language Models trên Amazon Bedrock cho Thực thi Tác vụ Đa bước Blog 2 - Cập nhật phương pháp Carbon cho Công cụ Dấu Chân Carbon của Khách Hàng AWS (CCFT) Blog 3 - Sử dụng thông tin tham chiếu dịch vụ AWS để tự động hóa luồng công việc quản lý chính sách "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/5-workshop/5.4-lambda-and-notification/",
	"title": "Lambda-and-notification",
	"tags": [],
	"description": "",
	"content": "Lambda Processing + Notification API Gateway → Lambda API Gateway nhận webhook từ SonarQube và chuyển payload cho Lambda.\nLambda thực hiện:\nParse dữ liệu từ SonarQube. Format message (project, loại lỗi, mức độ nghiêm trọng). Gửi nội dung sang SNS topic. SNS Notifications SNS gửi email đến nhóm dev:\nBáo lỗi bảo mật. Báo lỗi code. Báo fail Quality Gate. Link trực tiếp tới dashboard SonarQube. Lợi ích:\nDev biết lỗi ngay lập tức. Giảm thời gian debug. Tăng chất lượng và tính an toàn của phần mềm. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 4 Objectives: Nắm toàn bộ kiến thức về EC2. Thực hành tạo EC2, AMI, EBS. Tìm hiểu Autoscaling \u0026amp; Load Balancer. Làm lab backup EC2 bằng AWS Backup. Tasks this week: Day Task Start End Reference 2 Xem Module 03-01: EC2 InstancesEC2 Types, Pricing, AMI 29/09 29/09 FCJ Module 03 3 Tạo EC2 + EBSUser Data, Metadata 30/09 30/09 EC2 Docs 4 Thực hành Load BalancerAutoscaling Group 01/10 01/10 EC2 Labs 5 Làm Lab Backup (Lab13)Tạo backup plan 02/10 02/10 AWS Backup 6 Restore EC2 từ Backup 03/10 03/10 Backup Lab Week 4 Achievements: Hiểu mọi thành phần của EC2. Thành thạo Auto Scaling + Load Balancer. Triển khai được cơ chế backup toàn bộ EC2. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " Trong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: AI/ML/GenAI on AWS\nThời gian: 8:30 AM – 12:00 PM, Thứ Bảy, ngày 15/11/2025\nĐịa điểm: Tầng 36, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: DevOps on AWS\nThời gian: 8:30 AM – 5:00 PM, Thứ Hai, 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: AWS Well-Architected Security Pillar\nThời gian: 08:30 AM – 12:00 PM, 29/11/2025 — Buổi sáng\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/5-workshop/5.5-closed-loop-devsecops/",
	"title": "Closed-loop-devsecops",
	"tags": [],
	"description": "",
	"content": "DevSecOps Feedback Loop (Closed Cycle) Hệ thống tạo ra một vòng lặp DevSecOps khép kín: Dev commit code → GitLab ↓ CodePipeline chạy → CodeBuild quét → SonarQube phân tích ↓ Webhook → Lambda → SNS gửi email ↓ Dev nhận lỗi → Fix → Commit lại ↓ Quay lại vòng lặp\nLợi ích chính Tự động phát hiện bug và lỗ hổng bảo mật. Cảnh báo real-time giúp dev sửa ngay. Bảo đảm chất lượng code xuyên suốt vòng đời phát triển. Văn hóa DevSecOps được áp dụng thực tế: “Security shift-left”. Kết luận Pipeline đảm bảo một quy trình phát triển hiện đại, tự động, bảo mật và bền vững. Mỗi commit đều được phân tích nghiêm ngặt, giúp đội dev luôn duy trì chuẩn chất lượng cao.\n"
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "DevSecOps Security Scan Pipeline trên AWS Tổng quan Trong workshop này, chúng em xây dựng một pipeline DevSecOps trên AWS nhằm tích hợp bảo mật vào ngay trong quy trình CI/CD thay vì xử lý thủ công ở cuối dự án. Mỗi lần developer đẩy code lên repository, hệ thống sẽ tự động kích hoạt các bước kiểm tra bảo mật và chất lượng mã nguồn.\nMục tiêu chính Tự động quét lỗ hổng bảo mật sau mỗi lần commit/push code.Thực hiện quét container image và dependency bằng Trivy, giúp phát hiện lỗ hổng trong thư viện và base image.Chạy Bandit để kiểm tra các vấn đề bảo mật trong code Python/JavaScript.Tích hợp SonarQube để đánh giá chất lượng code (code smells, duplication, coverage, maintainability…).Đẩy các phát hiện quan trọng lên AWS Security Hub để tập trung quản lý cảnh báo bảo mật.Gửi thông báo real-time (qua Email/SNS/Chat…) khi phát hiện vấn đề nghiêm trọng để đội phát triển xử lý kịp thời.\nNội dung Tổng quan về workshop Pipline flow Sonarqube analysis Lambda and notification Close loop devsecops "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 5 Objectives: Làm chủ S3: bucket, object, ACL, versioning. Tạo static website hosting. Sử dụng CloudFront phân phối nội dung. Tasks this week: Day Task Start End Reference 2 Xem Module 04-02: S3 BasicsTạo bucket 06/10 06/10 S3 Docs 3 Static Website HostingPublic Access Block 07/10 07/10 S3 Lab 4 Tạo CloudFront Distribution 08/10 08/10 CloudFront Docs 5 Bật VersioningCross-region replication 09/10 09/10 S3 Advanced 6 Kiểm tra website + CloudFront 10/10 10/10 Lab Test Week 5 Achievements: Tạo và quản lý S3 thành thạo. Host được static website hoàn chỉnh. Sử dụng CloudFront để phân phối nội dung nhanh hơn. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 6 Objectives: Hiểu IAM nâng cao: Role, Policy, Resource Access. Thực hành tạo IAM Role cho Lambda, EC2. Tìm hiểu Security Hub \u0026amp; GuardDuty. Tasks this week: Day Task Start End Reference 2 Module 05-01 → 05-03: IAM, Cognito 13/10 13/10 Module 05 3 Tạo IAM Role cho EC2 + LambdaInline Policy vs Managed Policy 14/10 14/10 IAM Docs 4 Thử Switch RoleKiểm tra Policy bằng IAM Policy Simulator 15/10 15/10 IAM Tools 5 Bật Security HubBật GuardDuty 16/10 16/10 AWS Security 6 Tổng hợp kiến thức Security cơ bản 17/10 17/10 Notes Week 6 Achievements: Thành thạo IAM nâng cao. Hiểu security baseline của AWS. Biết bật và đọc kết quả Security Hub + GuardDuty. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong thời gian thực tập tại Amazon Web Services Vietnam Co., Ltd. từ 8/9/2025 đến 12/12/2025, tôi có cơ hội tiếp cận môi trường làm việc chuyên nghiệp và được thực hành những kiến thức đã học trong nhà trường.\nTôi tham gia chương trình First Cloud Journey, qua đó nâng cao kỹ năng giao tiếp, làm việc nhóm, quản lý thời gian, đồng thời mở rộng hiểu biết về AWS, Cloud Computing và các quy trình triển khai thực tế.\nTrong suốt quá trình thực tập, tôi luôn cố gắng hoàn thành công việc đúng tiến độ, tôn trọng nội quy và chủ động trao đổi với mentor và các bạn trong nhóm để cải thiện chất lượng công việc.\nDưới đây là phần tự đánh giá của tôi:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức \u0026amp; kỹ năng chuyên môn Áp dụng kiến thức AWS/Cloud vào thực tế, nắm vững công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Học nhanh, tự cập nhật thông tin, tiếp thu tốt các công nghệ mới ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu nhiệm vụ, không phụ thuộc vào hướng dẫn 100% ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng thời gian, đảm bảo độ chính xác ✅ ☐ ☐ 5 Kỷ luật Tuân thủ quy trình, giờ giấc, tác phong làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận góp ý, sửa sai và cải thiện năng lực ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng rõ ràng, trao đổi hợp tác ☐ ✅ ☐ 8 Làm việc nhóm Hỗ trợ nhóm, phối hợp nhịp nhàng trong dự án ✅ ☐ ☐ 9 Tác phong chuyên nghiệp Ứng xử chuẩn mực, tôn trọng mọi người ✅ ☐ ☐ 10 Giải quyết vấn đề Xử lý tình huống, đề xuất hướng giải quyết khi gặp lỗi/hạn chế ☐ ✅ ☐ 11 Đóng góp dự án Hoàn thành các task được giao, góp phần vào tiến độ và chất lượng dự án ☐ ✅ ☐ 12 Đánh giá chung Mức độ hoàn thành kỳ thực tập ☐ ✅ ☐ Những điểm cần cải thiện: Rèn luyện tính kỷ luật để làm việc ổn định và nhất quán hơn. Tăng khả năng phân tích và giải quyết vấn đề trong các tình huống phát sinh. Tập phản xạ nhanh và an toàn hơn khi xử lý lỗi kỹ thuật. Đặt mục tiêu rõ ràng và theo dõi tiến độ chặt chẽ hơn trong từng giai đoạn. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 7 Objectives: Tìm hiểu cơ bản về database trên AWS. Làm quen Amazon RDS, Aurora, DynamoDB. Hiểu backup, restore và security cho database. Thực hành Module 06. Tasks to be carried out this week: Day Task Start End Reference 2 Xem Module 06-01 → 06-02Hiểu RDS \u0026amp; Aurora 20/10 20/10 Module 06 3 Tạo RDS Subnet GroupTạo Security Group cho DB 21/10 21/10 RDS Lab 4 Tạo RDS InstanceKết nối thử bằng EC2 22/10 22/10 Lab 05 5 Làm backup \u0026amp; restore DBTìm hiểu snapshot 23/10 23/10 RDS Docs 6 Tìm hiểu DynamoDB \u0026amp; ElastiCache 24/10 24/10 NoSQL Docs Week 7 Achievements: Hiểu khác biệt SQL vs NoSQL trên AWS. Tạo được RDS Database \u0026amp; kết nối bằng EC2. Biết cấu hình backup, snapshot và restore DB. Làm quen DynamoDB và ElastiCache. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/7-feedback/",
	"title": "Chia sẻ &amp; Đánh giá cá nhân",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nKhông khí làm việc ở FCJ rất thoải mái và dễ hòa nhập. Mọi người thân thiện, sẵn sàng hỗ trợ mỗi khi mình gặp vấn đề, kể cả ngoài giờ học. Không gian làm việc cũng gọn gàng, tạo cảm giác tập trung hơn. Nếu có thêm một vài hoạt động kết nối hoặc giao lưu giữa các thành viên thì sẽ càng tốt.\n2. Sự hỗ trợ từ mentor / team admin\nMentor hướng dẫn khá chi tiết, giải thích rõ ràng từng bước và luôn để mình thử tự xử lý trước khi hỗ trợ. Team admin hỗ trợ về tài liệu, thông tin cần thiết và tạo điều kiện thuận lợi trong suốt kỳ thực tập. Điều mình thích nhất là mentor luôn động viên mình đặt câu hỏi và không ngại thắc mắc.\n3. Sự phù hợp giữa công việc và chuyên ngành\nCác nhiệm vụ trong kỳ thực tập phù hợp với những kiến thức mình đã học, đồng thời mở thêm nhiều mảng mới về cloud và DevOps mà trước đây mình chưa được tiếp cận. Nhờ vậy, mình có cơ hội vừa củng cố kiến thức nền vừa rèn luyện kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển bản thân\nTrong thời gian thực tập, mình học được cách sử dụng nhiều công cụ mới, cách làm việc nhóm hiệu quả hơn và cách giao tiếp trong môi trường chuyên nghiệp. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế về ngành cloud giúp mình hiểu rõ hơn định hướng nghề nghiệp tương lai.\n5. Văn hóa \u0026amp; tinh thần làm việc\nTập thể FCJ làm việc rất tích cực và hỗ trợ nhau tốt. Mọi người tôn trọng nhau và luôn giữ thái độ vui vẻ dù khối lượng công việc đôi khi nhiều. Điều này giúp mình cảm thấy gắn kết hơn và tự tin hơn khi làm việc chung.\n6. Chính sách \u0026amp; phúc lợi cho thực tập sinh\nTuy không có hỗ trợ về phụ cấp, nhưng bù lại lịch học linh hoạt và có cơ hội tham gia nhiều buổi training nội bộ nên vẫn rất hữu ích đối với mình.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong kỳ thực tập?\nĐược mentor hướng dẫn tận tình và chỉ rõ những điểm cần cải thiện, giúp mình tiến bộ hơn từng tuần. Công ty nên cải thiện gì cho các thực tập sinh sau?\nHiện tại mình chưa có đề xuất gì đặc biệt. Bạn có sẵn sàng giới thiệu bạn bè thực tập ở đây không? Vì sao?\nCó. Vì chương trình FCJ thực sự bổ ích, giúp hiểu rõ hơn về AWS và kỹ năng nghề nghiệp. Đề xuất và mong muốn Bạn có đề xuất gì để cải thiện kỳ thực tập?\nNếu được lên văn phòng AWS thường xuyên hơn thì mình nghĩ trải nghiệm sẽ càng tốt hơn. Bạn có muốn tiếp tục chương trình này trong tương lai?\nCó, vì AWS là một môi trường lớn, chuyên nghiệp và phù hợp với định hướng nghề nghiệp liên quan đến cloud trong tương lai. Góp ý thêm (tự do chia sẻ):\nKhông có góp ý gì thêm ngoài lời cảm ơn mentor và các anh chị trong FCJ đã hỗ trợ mình trong suốt thời gian thực tập. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 8 Objectives: Bắt đầu triển khai dự án “Security Scan Pipeline on AWS Cloud”. Hiểu yêu cầu dự án và chia vai trò trong nhóm. Phân tích kiến trúc DevSecOps Pipeline. Chuẩn bị repo GitHub và tài liệu nền tảng. Tasks to be carried out this week: Day Task Start End Reference 2 Họp nhóm phân chia vai tròĐọc và phân tích proposal 27/10 27/10 Project Docs 3 Nghiên cứu kiến trúc DevSecOps PipelineCodePipeline, CodeBuild, CodeDeploy 28/10 28/10 AWS DevOps Docs 4 Tạo sơ đồ kiến trúc pipeline ban đầu 29/10 29/10 Draw.io 5 Tạo GitHub repo nhómPhân quyền thành viên 30/10 30/10 GitHub 6 Ôn buildspec.yml \u0026amp; appspec.ymlChuẩn bị IAM permissions 31/10 31/10 CI/CD Docs Week 8 Achievements: Hiểu rõ phạm vi dự án và yêu cầu kỹ thuật. Xây dựng được bản phác thảo kiến trúc pipeline. Chuẩn bị xong GitHub repository và tài liệu nền tảng. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 9 Objectives: Hoàn thiện kiến trúc Security Scan Pipeline. Tạo hạ tầng cơ bản trên AWS: IAM Roles, S3, EC2. Kết nối GitHub với CodePipeline. Tasks this week: Day Task Start End Reference 2 Hoàn chỉnh bản kiến trúc Pipeline 03/11 03/11 Project Docs 3 Tạo IAM Roles cho PipelineCodeBuildRole, CodeDeployRole 04/11 04/11 IAM Docs 4 Tạo S3 Artifact BucketBật Encryption 05/11 05/11 S3 Docs 5 Khởi tạo EC2 để deployCấu hình Security Group 06/11 06/11 EC2 Docs 6 Kết nối GitHub → CodePipelineCommit thử để test Source stage 07/11 07/11 GitHub Week 9 Achievements: Kiến trúc Pipeline hoàn thiện và rõ ràng. Hạ tầng core (IAM/S3/EC2) đã thiết lập đầy đủ. GitHub kết nối thành công với CodePipeline. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Xây dựng Pipeline hoàn chỉnh. Tích hợp CodeGuru Reviewer để quét bảo mật. Tạo buildspec.yml và appspec.yml. Tasks this week: Day Task Start End Reference 2 Tạo CodePipeline các stage: Source → Build → Scan → Deploy 10/11 10/11 AWS CodePipeline 3 Cấu hình CodeBuild + buildspec.yml 11/11 11/11 CodeBuild Docs 4 Tích hợp CodeGuru Reviewer 12/11 12/11 CodeGuru Docs 5 Tạo appspec.yml 13/11 13/11 CodeDeploy Docs 6 Chạy thử Pipeline — sửa lỗi IAM 14/11 14/11 Troubleshooting Notes Week 10 Achievements: Pipeline chạy được 3 stage đầu (Source/Build/Scan). CodeGuru Reviewer đã tự động quét mã và phát hiện vấn đề. Cấu hình CodeDeploy đã sẵn sàng. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Hoàn thiện giai đoạn Deploy. Test pipeline end-to-end. Fix lỗi và tối ưu workflow. Tasks this week: Day Task Start End Reference 2 Cấu hình CodeDeploy Application + Deployment Group 17/11 17/11 CodeDeploy Docs 3 Kiểm tra AppSpec Hooks 18/11 18/11 AppSpec Docs 4 Chạy thử Pipeline đầu tiên → lỗi Permission EC2 19/11 19/11 Test Logs 5 Sửa IAM Role + update appspec 20/11 20/11 Troubleshooting 6 Kích hoạt CloudWatch, GuardDuty, Security Hub 21/11 21/11 AWS Security Tools Week 11 Achievements: Deploy EC2 thành công qua CodeDeploy. Pipeline chạy trơn tru toàn bộ quy trình. Bật xong hệ thống giám sát và bảo mật. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Hoàn thiện tài liệu dự án. Tổng hợp log, báo cáo test và lỗi. Chuẩn bị slide thuyết trình. Hoàn thành full báo cáo thực tập. Tasks this week: Day Task Start End Reference 2 Thu thập log pipeline (CloudWatch) 24/11 24/11 CloudWatch 3 Viết tài liệu hướng dẫn vận hành pipeline 25/11 25/11 Project Docs 4 Tạo gói bàn giao (architecture, configs, diagrams) 26/11 26/11 Deliverables 5 Viết báo cáo lỗi \u0026amp; cách khắc phục 27/11 27/11 Troubleshooting 6 Tạo slide thuyết trình \u0026amp; rà soát cả Worklog Week 1–12 28/11 28/11 Final Review Week 12 Achievements: Hoàn thành tất cả tài liệu dự án. Có đầy đủ log/test/error để trình bày. Pipeline hoàn chỉnh và bàn giao đầy đủ. Báo cáo thực tập đã hoàn thiện. "
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://minhDuong27.github.io/fcj-workshop2/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]